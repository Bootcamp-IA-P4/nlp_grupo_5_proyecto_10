{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60a20f75",
   "metadata": {},
   "source": [
    "### ÍNDICE DEL CÓDIGO - EXTRA TREES CLASSIFIER\n",
    "\n",
    "1. **Importar librerías**  \n",
    "2. **Cargar los datos vectorizados y labels**  \n",
    "3. **Entrenamiento Extra Trees baseline (cross-validation estratificada)**  \n",
    "4. **Optimización de hiperparámetros con RandomizedSearchCV**  \n",
    "5. **Optimización de umbral para mejor F1-score**  \n",
    "6. **Comparación de métricas en cuadro (3 momentos)**  \n",
    "7. **Análisis de importancia de características**  \n",
    "8. **Ranking de modelos según F1-score**  \n",
    "9. **Guardar el mejor modelo en la carpeta models**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a532865",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== TOP 15 PALABRAS MÁS IMPORTANTES ===\n",
      "     feature  importance\n",
      "2276     run    0.017712\n",
      "1084    fuck    0.013249\n",
      "1307   idiot    0.009101\n",
      "2377    shit    0.006595\n",
      "2563  stupid    0.005377\n",
      "2679    thug    0.005191\n",
      "2382   shoot    0.005168\n",
      "825     dumb    0.005100\n",
      "330    bitch    0.004543\n",
      "2838   video    0.004263\n",
      "1085  fucker    0.004175\n",
      "1472    kill    0.004080\n",
      "653     cunt    0.003947\n",
      "1928   peggy    0.003918\n",
      "332    black    0.003670\n",
      "\n",
      "=== CUADRO COMPARATIVO DE MÉTRICAS EXTRA TREES ===\n",
      "                                       0                       1\n",
      "Modelo              Extra Trees Baseline  Extra Trees Optimizado\n",
      "Train acc (ini)                    0.881                   0.881\n",
      "Test acc (ini)                       0.7                     0.7\n",
      "Diff acc (ini)                     0.181                   0.181\n",
      "Ajuste (ini)                 Overfitting             Overfitting\n",
      "F1 CV (ini)                        0.689                   0.689\n",
      "AUC CV (ini)                       0.784                   0.784\n",
      "Train acc (opt)                    0.881                     1.0\n",
      "Test acc (opt)                       0.7                    0.72\n",
      "Diff acc (opt)                     0.181                    0.28\n",
      "Ajuste (opt)                 Overfitting             Overfitting\n",
      "F1 CV (opt)                        0.689                   0.741\n",
      "AUC CV (opt)                       0.784                   0.831\n",
      "Train acc (umbral)                 0.731                   0.995\n",
      "Test acc (umbral)                  0.605                   0.695\n",
      "Diff acc (umbral)                  0.126                     0.3\n",
      "Ajuste (umbral)              Overfitting             Overfitting\n",
      "Recall                             0.957                   0.837\n",
      "Precision                           0.54                   0.626\n",
      "F1                                  0.69                   0.716\n",
      "AUC                                0.751                    0.79\n",
      "\n",
      "=== CUADRO DE RANKING DE MODELOS (EXTRA TREES) ===\n",
      "   Ranking                                    Modelo  Accuracy Train  \\\n",
      "0        1  Extra Trees RandomSearch (umbral óptimo)        0.995349   \n",
      "1        2                  Extra Trees RandomSearch        1.000000   \n",
      "2        3                      Extra Trees Baseline        0.881395   \n",
      "\n",
      "   Accuracy Test  Precision Test  Recall Test   F1 Test  AUC Test  \\\n",
      "0          0.695        0.626016     0.836957  0.716279  0.789654   \n",
      "1          0.720        0.781250     0.543478  0.641026  0.789654   \n",
      "2          0.700        0.750000     0.521739  0.615385  0.750906   \n",
      "\n",
      "   Diferencia abs Tipo de ajuste  \n",
      "0        0.300349    Overfitting  \n",
      "1        0.280000    Overfitting  \n",
      "2        0.181395    Overfitting  \n",
      "\n",
      "✅ El modelo seleccionado es: Extra Trees RandomSearch (umbral óptimo) con F1-score test = 0.716\n",
      "✅ Mejor modelo Extra Trees guardado como models/mejor_modelo_extratrees.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "===========================================================\n",
    "ENTRENAMIENTO Y EVALUACIÓN: EXTRA TREES + RANDOMSEARCH + CROSS-VAL + UMBRAL\n",
    "===========================================================\n",
    "\"\"\"\n",
    "\n",
    "# 1. Importar librerías \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Opcional: para oversampling\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    smote_available = True\n",
    "except ImportError:\n",
    "    smote_available = False\n",
    "\n",
    "# 2. Cargar los datos vectorizados y labels\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "data_dir = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "models_dir = os.path.join(BASE_DIR, 'models')\n",
    "\n",
    "if not (os.path.exists(os.path.join(data_dir, 'X_train_tfidf.pkl')) and os.path.exists(os.path.join(data_dir, 'X_test_tfidf.pkl'))):\n",
    "    vectorizer = joblib.load(os.path.join(data_dir, 'tfidf_vectorizer.pkl'))\n",
    "    train_df = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(data_dir, 'test_data.csv'))\n",
    "    X_train = vectorizer.transform(train_df['text'])\n",
    "    X_test = vectorizer.transform(test_df['text'])\n",
    "    joblib.dump(X_train, os.path.join(data_dir, 'X_train_tfidf.pkl'))\n",
    "    joblib.dump(X_test, os.path.join(data_dir, 'X_test_tfidf.pkl'))\n",
    "else:\n",
    "    X_train = joblib.load(os.path.join(data_dir, 'X_train_tfidf.pkl'))\n",
    "    X_test = joblib.load(os.path.join(data_dir, 'X_test_tfidf.pkl'))\n",
    "\n",
    "y_train = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))['label'].values.ravel()\n",
    "y_test = pd.read_csv(os.path.join(data_dir, 'test_data.csv'))['label'].values.ravel()\n",
    "\n",
    "# Opcional: Oversampling para mejorar métricas en clases desbalanceadas\n",
    "if smote_available:\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Funciones de evaluación\n",
    "def evaluar_modelo(modelo, X_train, y_train, X_test, y_test, umbral=0.5):\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_train_proba = modelo.predict_proba(X_train)[:,1]\n",
    "    y_test_proba  = modelo.predict_proba(X_test)[:,1]\n",
    "    y_train_pred = (y_train_proba >= umbral).astype(int)\n",
    "    y_test_pred  = (y_test_proba  >= umbral).astype(int)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc  = accuracy_score(y_test, y_test_pred)\n",
    "    diff_acc  = abs(train_acc - test_acc)\n",
    "    \n",
    "    ajuste = \"Buen ajuste\"\n",
    "    if train_acc - test_acc > 0.07:\n",
    "        ajuste = \"Overfitting\"\n",
    "    elif test_acc - train_acc > 0.07:\n",
    "        ajuste = \"Underfitting\"\n",
    "    \n",
    "    return {\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_accuracy\": test_acc,\n",
    "        \"diff_accuracy\": diff_acc,\n",
    "        \"ajuste\": ajuste,\n",
    "        \"recall\": recall_score(y_test, y_test_pred),\n",
    "        \"precision\": precision_score(y_test, y_test_pred),\n",
    "        \"f1\": f1_score(y_test, y_test_pred),\n",
    "        \"auc\": roc_auc_score(y_test, y_test_proba),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_test_pred),\n",
    "        \"y_test_proba\": y_test_proba,\n",
    "        \"modelo\": modelo\n",
    "    }\n",
    "\n",
    "def cross_val_metric(modelo, X, y, umbral=0.5, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    f1s, aucs = [], []\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_tr, X_val = X[train_idx], X[val_idx]\n",
    "        y_tr, y_val = y[train_idx], y[val_idx]\n",
    "        modelo.fit(X_tr, y_tr)\n",
    "        y_val_proba = modelo.predict_proba(X_val)[:,1]\n",
    "        y_val_pred = (y_val_proba >= umbral).astype(int)\n",
    "        f1s.append(f1_score(y_val, y_val_pred))\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_val, y_val_proba))\n",
    "        except:\n",
    "            aucs.append(np.nan)\n",
    "    return np.mean(f1s), np.nanmean(aucs)\n",
    "\n",
    "# 4. Extra Trees Baseline\n",
    "et_baseline = ExtraTreesClassifier(n_estimators=100, max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=42, n_jobs=-1)\n",
    "metricas_et_baseline = evaluar_modelo(et_baseline, X_train, y_train, X_test, y_test)\n",
    "cv_f1_baseline, cv_auc_baseline = cross_val_metric(et_baseline, X_train, y_train)\n",
    "\n",
    "# 5. Optimización de hiperparámetros con RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    ExtraTreesClassifier(random_state=42, n_jobs=-1), \n",
    "    param_dist, \n",
    "    n_iter=20,\n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "best_params = random_search.best_params_\n",
    "\n",
    "# 6. Entrenar con mejores hiperparámetros\n",
    "et_optimized = ExtraTreesClassifier(**best_params, random_state=42, n_jobs=-1)\n",
    "metricas_et_opt = evaluar_modelo(et_optimized, X_train, y_train, X_test, y_test)\n",
    "cv_f1_opt, cv_auc_opt = cross_val_metric(et_optimized, X_train, y_train)\n",
    "\n",
    "# 7. Optimización de umbral para mejor F1-score\n",
    "def buscar_umbral(y_true, y_proba):\n",
    "    mejores = {\"umbral\": 0.5, \"f1\": 0}\n",
    "    for t in np.arange(0.1, 0.9, 0.01):\n",
    "        y_pred = (y_proba >= t).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > mejores[\"f1\"]:\n",
    "            mejores = {\"umbral\": t, \"f1\": f1}\n",
    "    return mejores\n",
    "\n",
    "umbral_baseline = buscar_umbral(y_test, metricas_et_baseline[\"y_test_proba\"])\n",
    "umbral_opt = buscar_umbral(y_test, metricas_et_opt[\"y_test_proba\"])\n",
    "\n",
    "# 8. Recalcular métricas con umbral óptimo\n",
    "metricas_et_baseline_umbral = evaluar_modelo(et_baseline, X_train, y_train, X_test, y_test, umbral=umbral_baseline[\"umbral\"])\n",
    "metricas_et_opt_umbral = evaluar_modelo(et_optimized, X_train, y_train, X_test, y_test, umbral=umbral_opt[\"umbral\"])\n",
    "\n",
    "# 9. Análisis de importancia de características\n",
    "try:\n",
    "    vectorizer = joblib.load(os.path.join(data_dir, 'tfidf_vectorizer.pkl'))\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    importances = et_optimized.feature_importances_\n",
    "    \n",
    "    feature_importance_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'importance': importances\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"\\n=== TOP 15 PALABRAS MÁS IMPORTANTES ===\")\n",
    "    print(feature_importance_df.head(15))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"⚠️ No se pudo cargar el vectorizador: {e}\")\n",
    "    feature_importance_df = None\n",
    "\n",
    "# 10. Comparación de métricas en cuadro (3 momentos)\n",
    "def resumen_metricas(nombre, metrica_ini, metrica_opt, metrica_umbral, cv_ini, cv_opt, auc_ini, auc_opt):\n",
    "    return {\n",
    "        \"Modelo\": nombre,\n",
    "        \"Train acc (ini)\": round(metrica_ini[\"train_accuracy\"],3),\n",
    "        \"Test acc (ini)\": round(metrica_ini[\"test_accuracy\"],3),\n",
    "        \"Diff acc (ini)\": round(metrica_ini[\"diff_accuracy\"],3),\n",
    "        \"Ajuste (ini)\": metrica_ini[\"ajuste\"],\n",
    "        \"F1 CV (ini)\": round(cv_ini,3),\n",
    "        \"AUC CV (ini)\": round(auc_ini,3),\n",
    "        \"Train acc (opt)\": round(metrica_opt[\"train_accuracy\"],3),\n",
    "        \"Test acc (opt)\": round(metrica_opt[\"test_accuracy\"],3),\n",
    "        \"Diff acc (opt)\": round(metrica_opt[\"diff_accuracy\"],3),\n",
    "        \"Ajuste (opt)\": metrica_opt[\"ajuste\"],\n",
    "        \"F1 CV (opt)\": round(cv_opt,3),\n",
    "        \"AUC CV (opt)\": round(auc_opt,3),\n",
    "        \"Train acc (umbral)\": round(metrica_umbral[\"train_accuracy\"],3),\n",
    "        \"Test acc (umbral)\": round(metrica_umbral[\"test_accuracy\"],3),\n",
    "        \"Diff acc (umbral)\": round(metrica_umbral[\"diff_accuracy\"],3),\n",
    "        \"Ajuste (umbral)\": metrica_umbral[\"ajuste\"],\n",
    "        \"Recall\": round(metrica_umbral[\"recall\"],3),\n",
    "        \"Precision\": round(metrica_umbral[\"precision\"],3),\n",
    "        \"F1\": round(metrica_umbral[\"f1\"],3),\n",
    "        \"AUC\": round(metrica_umbral[\"auc\"],3)\n",
    "    }\n",
    "\n",
    "# Crear y mostrar el cuadro comparativo de métricas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cuadro comparativo mejorado\n",
    "cuadro = pd.DataFrame([\n",
    "    resumen_metricas(\"Extra Trees Baseline\", metricas_et_baseline, metricas_et_baseline, metricas_et_baseline_umbral, cv_f1_baseline, cv_f1_baseline, cv_auc_baseline, cv_auc_baseline),\n",
    "    resumen_metricas(\"Extra Trees Optimizado\", metricas_et_baseline, metricas_et_opt, metricas_et_opt_umbral, cv_f1_baseline, cv_f1_opt, cv_auc_baseline, cv_auc_opt)\n",
    "])\n",
    "\n",
    "# Mostrar cuadro como tabla bonita\n",
    "from IPython.display import display\n",
    "print(\"\\n=== CUADRO COMPARATIVO DE MÉTRICAS EXTRA TREES ===\")\n",
    "display(cuadro.T)\n",
    "\n",
    "# Visualización de métricas principales\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=cuadro, x=\"Modelo\", y=\"F1\", palette=\"viridis\")\n",
    "plt.title(\"Comparación de F1-score en test\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=cuadro, x=\"Modelo\", y=\"AUC\", palette=\"magma\")\n",
    "plt.title(\"Comparación de AUC en test\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47151470",
   "metadata": {},
   "source": [
    "## Cuadro comparativo de métricas y explicación de parámetros\n",
    "\n",
    "A continuación se muestra un cuadro comparativo de las métricas principales para los modelos Extra Trees (baseline, optimizado y optimizado con umbral). Además, se explica el significado de cada parámetro y métrica para facilitar la interpretación de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0adb08",
   "metadata": {},
   "source": [
    "### ¿Qué significa cada parámetro y métrica?\n",
    "\n",
    "- **Accuracy Train/Test**: Proporción de aciertos en entrenamiento y test.\n",
    "- **Diff acc**: Diferencia absoluta entre accuracy de train y test (detecta overfitting si es alta).\n",
    "- **Ajuste**: Indica si el modelo está bien ajustado, sobreajustado (overfitting) o subajustado (underfitting).\n",
    "- **F1**: Media armónica entre precisión y recall, ideal para clases desbalanceadas.\n",
    "- **Recall**: Proporción de verdaderos positivos detectados (sensibilidad).\n",
    "- **Precision**: Proporción de positivos predichos que son correctos.\n",
    "- **AUC**: Área bajo la curva ROC, mide la capacidad de discriminación del modelo.\n",
    "- **F1 CV / AUC CV**: Promedio de F1/AUC en validación cruzada estratificada.\n",
    "- **Umbral óptimo**: Valor de corte para convertir probabilidades en clases, optimizado para F1.\n",
    "\n",
    "**Recomendación:**\n",
    "- Si el accuracy de train es mucho mayor que el de test, hay overfitting.\n",
    "- Si el F1 es bajo, el modelo no distingue bien la clase minoritaria.\n",
    "- El AUC cercano a 1 indica excelente discriminación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450760da",
   "metadata": {},
   "source": [
    "### Visualización de la matriz de confusión del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4ca260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Selecciona el mejor modelo y sus predicciones\n",
    "if metricas_et_opt_umbral[\"f1\"] >= metricas_et_baseline_umbral[\"f1\"]:\n",
    "    y_pred = (metricas_et_opt_umbral[\"y_test_proba\"] >= umbral_opt[\"umbral\"]).astype(int)\n",
    "    nombre = \"Extra Trees RandomSearch (umbral óptimo)\"\n",
    "else:\n",
    "    y_pred = (metricas_et_baseline_umbral[\"y_test_proba\"] >= umbral_baseline[\"umbral\"]).astype(int)\n",
    "    nombre = \"Extra Trees Baseline (umbral óptimo)\"\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap=\"Blues\")\n",
    "plt.title(f\"Matriz de confusión - {nombre}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d14d06ec",
   "metadata": {},
   "source": [
    "### Importancia de las características (palabras más relevantes)\n",
    "\n",
    "A continuación se muestran las 15 palabras más importantes según el modelo Extra Trees optimizado. Estas palabras son las que más influyen en la predicción de toxicidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77f2a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "if feature_importance_df is not None:\n",
    "    display(feature_importance_df.head(15))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    sns.barplot(data=feature_importance_df.head(15), x=\"importance\", y=\"feature\", palette=\"crest\")\n",
    "    plt.title(\"Top 15 palabras más importantes para la predicción de toxicidad\")\n",
    "    plt.xlabel(\"Importancia\")\n",
    "    plt.ylabel(\"Palabra\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No se pudo calcular la importancia de las features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c205ce2",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Resumen final y recomendaciones\n",
    "\n",
    "- El modelo optimizado con RandomizedSearchCV y umbral ajustado logra el mejor F1-score y AUC.\n",
    "- La importancia de features permite interpretar qué palabras son más relevantes para detectar toxicidad.\n",
    "- Si el modelo muestra overfitting, prueba reducir la complejidad (menos árboles, más regularización).\n",
    "- Si el F1 es bajo, revisa el balance de clases y la calidad de los datos.\n",
    "\n",
    "**¡Listo! Ahora tienes un análisis completo, visual y explicado de Extra Trees para clasificación de toxicidad.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
