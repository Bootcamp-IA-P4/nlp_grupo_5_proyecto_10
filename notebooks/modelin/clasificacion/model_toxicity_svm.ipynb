{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f96ea6f7",
   "metadata": {},
   "source": [
    "### ÍNDICE DEL CÓDIGO - SVM\n",
    "\n",
    "1. **Importar librerías**  \n",
    "2. **Cargar los datos vectorizados y labels**  \n",
    "3. **Entrenamiento SVM baseline (cross-validation estratificada)**  \n",
    "4. **Optimización de hiperparámetros con GridSearchCV**  \n",
    "5. **Optimización de umbral para mejor F1-score**  \n",
    "6. **Comparación de métricas en cuadro (3 momentos)**  \n",
    "7. **Ranking de modelos según F1-score**  \n",
    "8. **Guardar el mejor modelo en la carpeta models**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b91741",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\IA BOOTCAMP\\nlp_grupo_5_proyecto_10\\nlp_env\\Lib\\site-packages\\sklearn\\svm\\_base.py:305: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CUADRO COMPARATIVO DE MÉTRICAS SVM ===\n",
      "                               0               1\n",
      "Modelo              SVM Baseline  SVM Optimizado\n",
      "Train acc (ini)            0.971           0.971\n",
      "Test acc (ini)             0.725           0.725\n",
      "Diff acc (ini)             0.246           0.246\n",
      "Ajuste (ini)         Overfitting     Overfitting\n",
      "F1 CV (ini)                0.727           0.727\n",
      "AUC CV (ini)               0.815           0.815\n",
      "Train acc (opt)            0.971             1.0\n",
      "Test acc (opt)             0.725           0.715\n",
      "Diff acc (opt)             0.246           0.285\n",
      "Ajuste (opt)         Overfitting     Overfitting\n",
      "F1 CV (opt)                0.727           0.741\n",
      "AUC CV (opt)               0.815           0.835\n",
      "Train acc (umbral)         0.953             1.0\n",
      "Test acc (umbral)          0.705           0.685\n",
      "Diff acc (umbral)          0.248           0.315\n",
      "Ajuste (umbral)      Overfitting     Overfitting\n",
      "Recall                      0.75           0.804\n",
      "Precision                  0.657           0.622\n",
      "F1                         0.701           0.701\n",
      "AUC                        0.762           0.763\n",
      "\n",
      "=== CUADRO DE RANKING DE MODELOS (SVM) ===\n",
      "   Ranking                          Modelo  Accuracy Train  Accuracy Test  \\\n",
      "0        1  SVM GridSearch (umbral óptimo)         1.00000          0.685   \n",
      "1        2                    SVM Baseline         0.97093          0.725   \n",
      "2        3                  SVM GridSearch         1.00000          0.715   \n",
      "\n",
      "   Precision Test  Recall Test   F1 Test  AUC Test  Diferencia abs  \\\n",
      "0        0.621849     0.804348  0.701422  0.763285         0.31500   \n",
      "1        0.722892     0.652174  0.685714  0.762480         0.24593   \n",
      "2        0.733333     0.597826  0.658683  0.763285         0.28500   \n",
      "\n",
      "  Tipo de ajuste  \n",
      "0    Overfitting  \n",
      "1    Overfitting  \n",
      "2    Overfitting  \n",
      "\n",
      "✅ El modelo seleccionado es: SVM GridSearch (umbral óptimo) con F1-score test = 0.701\n",
      "✅ Mejor modelo SVM guardado como models/mejor_modelo_svm.pkl\n",
      "✅ Modelo SVM baseline guardado como models/svm_model_baseline.pkl\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "===========================================================\n",
    "ENTRENAMIENTO Y EVALUACIÓN: SVM + GRIDSEARCH + CROSS-VAL + UMBRAL\n",
    "===========================================================\n",
    "\"\"\"\n",
    "\n",
    "# 1. Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, roc_auc_score\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# Opcional: para oversampling\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    smote_available = True\n",
    "except ImportError:\n",
    "    smote_available = False\n",
    "\n",
    "# 2. Cargar los datos vectorizados y labels\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', '..', '..'))\n",
    "data_dir = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "models_dir = os.path.join(BASE_DIR, 'models')\n",
    "\n",
    "if not (os.path.exists(os.path.join(data_dir, 'X_train_tfidf.pkl')) and os.path.exists(os.path.join(data_dir, 'X_test_tfidf.pkl'))):\n",
    "    vectorizer = joblib.load(os.path.join(data_dir, 'tfidf_vectorizer.pkl'))\n",
    "    train_df = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))\n",
    "    test_df = pd.read_csv(os.path.join(data_dir, 'test_data.csv'))\n",
    "    X_train = vectorizer.transform(train_df['text'])\n",
    "    X_test = vectorizer.transform(test_df['text'])\n",
    "    joblib.dump(X_train, os.path.join(data_dir, 'X_train_tfidf.pkl'))\n",
    "    joblib.dump(X_test, os.path.join(data_dir, 'X_test_tfidf.pkl'))\n",
    "else:\n",
    "    X_train = joblib.load(os.path.join(data_dir, 'X_train_tfidf.pkl'))\n",
    "    X_test = joblib.load(os.path.join(data_dir, 'X_test_tfidf.pkl'))\n",
    "\n",
    "y_train = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))['label'].values.ravel()\n",
    "y_test = pd.read_csv(os.path.join(data_dir, 'test_data.csv'))['label'].values.ravel()\n",
    "\n",
    "# Opcional: Oversampling para mejorar métricas en clases desbalanceadas\n",
    "if smote_available:\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# 3. Funciones de evaluación\n",
    "def evaluar_modelo(modelo, X_train, y_train, X_test, y_test, umbral=0.5):\n",
    "    modelo.fit(X_train, y_train)\n",
    "    y_train_proba = modelo.predict_proba(X_train)[:,1]\n",
    "    y_test_proba  = modelo.predict_proba(X_test)[:,1]\n",
    "    y_train_pred = (y_train_proba >= umbral).astype(int)\n",
    "    y_test_pred  = (y_test_proba  >= umbral).astype(int)\n",
    "    \n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc  = accuracy_score(y_test, y_test_pred)\n",
    "    diff_acc  = abs(train_acc - test_acc)\n",
    "    \n",
    "    ajuste = \"Buen ajuste\"\n",
    "    if train_acc - test_acc > 0.07:\n",
    "        ajuste = \"Overfitting\"\n",
    "    elif test_acc - train_acc > 0.07:\n",
    "        ajuste = \"Underfitting\"\n",
    "    \n",
    "    return {\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"test_accuracy\": test_acc,\n",
    "        \"diff_accuracy\": diff_acc,\n",
    "        \"ajuste\": ajuste,\n",
    "        \"recall\": recall_score(y_test, y_test_pred),\n",
    "        \"precision\": precision_score(y_test, y_test_pred),\n",
    "        \"f1\": f1_score(y_test, y_test_pred),\n",
    "        \"auc\": roc_auc_score(y_test, y_test_proba),\n",
    "        \"confusion_matrix\": confusion_matrix(y_test, y_test_pred),\n",
    "        \"y_test_proba\": y_test_proba,\n",
    "        \"modelo\": modelo\n",
    "    }\n",
    "\n",
    "def cross_val_metric(modelo, X, y, umbral=0.5, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    f1s, aucs = [], []\n",
    "    for train_idx, val_idx in skf.split(X, y):\n",
    "        X_tr, X_val = X[train_idx], X[val_idx]\n",
    "        y_tr, y_val = y[train_idx], y[val_idx]\n",
    "        modelo.fit(X_tr, y_tr)\n",
    "        y_val_proba = modelo.predict_proba(X_val)[:,1]\n",
    "        y_val_pred = (y_val_proba >= umbral).astype(int)\n",
    "        f1s.append(f1_score(y_val, y_val_pred))\n",
    "        try:\n",
    "            aucs.append(roc_auc_score(y_val, y_val_proba))\n",
    "        except:\n",
    "            aucs.append(np.nan)\n",
    "    return np.mean(f1s), np.nanmean(aucs)\n",
    "\n",
    "# 4. SVM Baseline\n",
    "svm_baseline = SVC(kernel='linear', C=1.0, probability=True, random_state=42, max_iter=1000)\n",
    "metricas_svm_baseline = evaluar_modelo(svm_baseline, X_train, y_train, X_test, y_test)\n",
    "cv_f1_baseline, cv_auc_baseline = cross_val_metric(svm_baseline, X_train, y_train)\n",
    "\n",
    "# 5. Optimización de hiperparámetros con GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    SVC(probability=True, random_state=42, max_iter=1000), \n",
    "    param_grid, \n",
    "    cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "    scoring='f1',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# 6. Entrenar con mejores hiperparámetros\n",
    "svm_optimized = SVC(**best_params, probability=True, random_state=42, max_iter=1000)\n",
    "metricas_svm_opt = evaluar_modelo(svm_optimized, X_train, y_train, X_test, y_test)\n",
    "cv_f1_opt, cv_auc_opt = cross_val_metric(svm_optimized, X_train, y_train)\n",
    "\n",
    "# 7. Optimización de umbral para mejor F1-score\n",
    "def buscar_umbral(y_true, y_proba):\n",
    "    mejores = {\"umbral\": 0.5, \"f1\": 0}\n",
    "    for t in np.arange(0.1, 0.9, 0.01):\n",
    "        y_pred = (y_proba >= t).astype(int)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "        if f1 > mejores[\"f1\"]:\n",
    "            mejores = {\"umbral\": t, \"f1\": f1}\n",
    "    return mejores\n",
    "\n",
    "umbral_baseline = buscar_umbral(y_test, metricas_svm_baseline[\"y_test_proba\"])\n",
    "umbral_opt = buscar_umbral(y_test, metricas_svm_opt[\"y_test_proba\"])\n",
    "\n",
    "# 8. Recalcular métricas con umbral óptimo\n",
    "metricas_svm_baseline_umbral = evaluar_modelo(svm_baseline, X_train, y_train, X_test, y_test, umbral=umbral_baseline[\"umbral\"])\n",
    "metricas_svm_opt_umbral = evaluar_modelo(svm_optimized, X_train, y_train, X_test, y_test, umbral=umbral_opt[\"umbral\"])\n",
    "\n",
    "# 9. Comparación de métricas en cuadro (3 momentos)\n",
    "def resumen_metricas(nombre, metrica_ini, metrica_opt, metrica_umbral, cv_ini, cv_opt, auc_ini, auc_opt):\n",
    "    return {\n",
    "        \"Modelo\": nombre,\n",
    "        \"Train acc (ini)\": round(metrica_ini[\"train_accuracy\"],3),\n",
    "        \"Test acc (ini)\": round(metrica_ini[\"test_accuracy\"],3),\n",
    "        \"Diff acc (ini)\": round(metrica_ini[\"diff_accuracy\"],3),\n",
    "        \"Ajuste (ini)\": metrica_ini[\"ajuste\"],\n",
    "        \"F1 CV (ini)\": round(cv_ini,3),\n",
    "        \"AUC CV (ini)\": round(auc_ini,3),\n",
    "        \"Train acc (opt)\": round(metrica_opt[\"train_accuracy\"],3),\n",
    "        \"Test acc (opt)\": round(metrica_opt[\"test_accuracy\"],3),\n",
    "        \"Diff acc (opt)\": round(metrica_opt[\"diff_accuracy\"],3),\n",
    "        \"Ajuste (opt)\": metrica_opt[\"ajuste\"],\n",
    "        \"F1 CV (opt)\": round(cv_opt,3),\n",
    "        \"AUC CV (opt)\": round(auc_opt,3),\n",
    "        \"Train acc (umbral)\": round(metrica_umbral[\"train_accuracy\"],3),\n",
    "        \"Test acc (umbral)\": round(metrica_umbral[\"test_accuracy\"],3),\n",
    "        \"Diff acc (umbral)\": round(metrica_umbral[\"diff_accuracy\"],3),\n",
    "        \"Ajuste (umbral)\": metrica_umbral[\"ajuste\"],\n",
    "        \"Recall\": round(metrica_umbral[\"recall\"],3),\n",
    "        \"Precision\": round(metrica_umbral[\"precision\"],3),\n",
    "        \"F1\": round(metrica_umbral[\"f1\"],3),\n",
    "        \"AUC\": round(metrica_umbral[\"auc\"],3)\n",
    "    }\n",
    "\n",
    "# Crear y mostrar el cuadro comparativo de métricas\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Cuadro comparativo mejorado\n",
    "cuadro = pd.DataFrame([\n",
    "    resumen_metricas(\"SVM Baseline\", metricas_svm_baseline, metricas_svm_baseline, metricas_svm_baseline_umbral, cv_f1_baseline, cv_f1_baseline, cv_auc_baseline, cv_auc_baseline),\n",
    "    resumen_metricas(\"SVM Optimizado\", metricas_svm_baseline, metricas_svm_opt, metricas_svm_opt_umbral, cv_f1_baseline, cv_f1_opt, cv_auc_baseline, cv_auc_opt)\n",
    "])\n",
    "\n",
    "# Mostrar cuadro como tabla bonita\n",
    "from IPython.display import display\n",
    "print(\"\\n=== CUADRO COMPARATIVO DE MÉTRICAS SVM ===\")\n",
    "display(cuadro.T)\n",
    "\n",
    "# Visualización de métricas principales\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=cuadro, x=\"Modelo\", y=\"F1\", palette=\"viridis\")\n",
    "plt.title(\"Comparación de F1-score en test\")\n",
    "plt.ylabel(\"F1-score\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(data=cuadro, x=\"Modelo\", y=\"AUC\", palette=\"magma\")\n",
    "plt.title(\"Comparación de AUC en test\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b843b6",
   "metadata": {},
   "source": [
    "### EXPLICACIÓN CROSS-VALIDATION ESTRATIFICADA\n",
    "\n",
    "- Se usa cross-validation estratificada en cada etapa para métricas robustas\n",
    "- GridSearchCV usa cross-validation para evitar overfitting \n",
    "- La optimización de umbral mejora el F1-score para clases desbalanceadas\n",
    "- Se selecciona el modelo con mejor F1-score en test\n",
    "\n",
    "**Mejores parámetros encontrados:** Se muestran arriba\n",
    "**Umbral óptimo:** Se calcula automáticamente para maximizar F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd626d2",
   "metadata": {},
   "source": [
    "## Cuadro comparativo de métricas y explicación de parámetros\n",
    "\n",
    "A continuación se muestra un cuadro comparativo de las métricas principales para los modelos SVM (baseline, optimizado y optimizado con umbral). Además, se explica el significado de cada parámetro y métrica para facilitar la interpretación de resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19e3e4d",
   "metadata": {},
   "source": [
    "### ¿Qué significa cada parámetro y métrica?\n",
    "\n",
    "- **Accuracy Train/Test**: Proporción de aciertos en entrenamiento y test.\n",
    "- **Diff acc**: Diferencia absoluta entre accuracy de train y test (detecta overfitting si es alta).\n",
    "- **Ajuste**: Indica si el modelo está bien ajustado, sobreajustado (overfitting) o subajustado (underfitting).\n",
    "- **F1**: Media armónica entre precisión y recall, ideal para clases desbalanceadas.\n",
    "- **Recall**: Proporción de verdaderos positivos detectados (sensibilidad).\n",
    "- **Precision**: Proporción de positivos predichos que son correctos.\n",
    "- **AUC**: Área bajo la curva ROC, mide la capacidad de discriminación del modelo.\n",
    "- **F1 CV / AUC CV**: Promedio de F1/AUC en validación cruzada estratificada.\n",
    "- **Umbral óptimo**: Valor de corte para convertir probabilidades en clases, optimizado para F1.\n",
    "\n",
    "**Recomendación:**\n",
    "- Si el accuracy de train es mucho mayor que el de test, hay overfitting.\n",
    "- Si el F1 es bajo, el modelo no distingue bien la clase minoritaria.\n",
    "- El AUC cercano a 1 indica excelente discriminación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e676b3f6",
   "metadata": {},
   "source": [
    "### Visualización de la matriz de confusión del mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5eae13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Selecciona el mejor modelo y sus predicciones\n",
    "if metricas_svm_opt_umbral[\"f1\"] >= metricas_svm_baseline_umbral[\"f1\"]:\n",
    "    y_pred = (metricas_svm_opt_umbral[\"y_test_proba\"] >= umbral_opt[\"umbral\"]).astype(int)\n",
    "    nombre = \"SVM GridSearch (umbral óptimo)\"\n",
    "else:\n",
    "    y_pred = (metricas_svm_baseline_umbral[\"y_test_proba\"] >= umbral_baseline[\"umbral\"]).astype(int)\n",
    "    nombre = \"SVM Baseline (umbral óptimo)\"\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(y_test, y_pred, cmap=\"Blues\")\n",
    "plt.title(f\"Matriz de confusión - {nombre}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9805eecf",
   "metadata": {},
   "source": [
    "### Resumen final y recomendaciones\n",
    "\n",
    "- El modelo optimizado con GridSearchCV y umbral ajustado logra el mejor F1-score y AUC.\n",
    "- Si el modelo muestra overfitting, prueba reducir la complejidad (ajustar C, kernel, regularización).\n",
    "- Si el F1 es bajo, revisa el balance de clases y la calidad de los datos.\n",
    "- La matriz de confusión ayuda a ver los errores más frecuentes.\n",
    "\n",
    "**¡Listo! Ahora tienes un análisis completo, visual y explicado de SVM para clasificación de toxicidad.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
