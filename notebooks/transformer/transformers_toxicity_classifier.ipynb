{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4848388",
   "metadata": {},
   "source": [
    "# Clasificación de Toxicidad con Transformers\n",
    "\n",
    "Este notebook implementa un clasificador de toxicidad usando arquitecturas de transformers a través de la biblioteca Hugging Face Transformers.\n",
    "\n",
    "## ¿Qué son los Transformers?\n",
    "\n",
    "Los transformers son una arquitectura de redes neuronales que ha revolucionado el procesamiento de lenguaje natural (NLP) en los últimos años. A diferencia de las redes neuronales tradicionales, los transformers usan un mecanismo llamado \"atención\" (attention) que les permite entender mejor las relaciones entre palabras en un texto, independientemente de su posición.\n",
    "\n",
    "## Ventajas de los Transformers sobre PyTorch tradicional\n",
    "\n",
    "Mientras que en el notebook anterior usamos una red neuronal simple con PyTorch, aquí usaremos transformers que ofrecen:\n",
    "\n",
    "1. **Comprensión contextual del lenguaje**: Entienden el significado de las palabras según el contexto.\n",
    "2. **Pre-entrenamiento**: Vienen pre-entrenados en enormes volúmenes de texto, lo que les da una comprensión general del lenguaje.\n",
    "3. **Fine-tuning**: Podemos ajustarlos fácilmente a nuestro problema específico con pocos datos.\n",
    "4. **Estado del arte**: Son los modelos que mejor rendimiento obtienen actualmente en tareas de NLP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "49a4bd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import joblib\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Librerías específicas de Transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0c9226f",
   "metadata": {},
   "source": [
    "## 1. Configuración inicial\n",
    "\n",
    "A diferencia del notebook anterior que usaba vectores TF-IDF, aquí trabajaremos directamente con los textos originales, ya que los transformers procesan texto sin necesidad de una vectorización previa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1b05819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verificando rutas:\n",
      "BASE_DIR: True\n",
      "data_dir: True\n",
      "models_dir: True\n",
      "Columnas en train_data: ['text', 'label']\n",
      "Datos de entrenamiento: (800, 2)\n",
      "Datos de prueba: (200, 2)\n",
      "\n",
      "Columnas en el dataset:\n",
      "['text', 'label']\n",
      "\n",
      "Primeras filas del dataset:\n",
      "                                                text  label\n",
      "0  wonder police expect happen continually abuse ...      1\n",
      "1    basset think walmart hire holiday get job loser      1\n",
      "2                                  anybody get cigar      0\n",
      "3               monkey scream bout honkie intensifie      1\n",
      "4  53 see brick hit white pig helmet laugh ass ni...      1\n",
      "\n",
      "Distribución de clases:\n",
      "label\n",
      "0    430\n",
      "1    370\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Configuramos las rutas\n",
    "import os\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..', '..'))\n",
    "data_dir = os.path.join(BASE_DIR, 'data', 'processed')\n",
    "models_dir = os.path.join(BASE_DIR, 'models')\n",
    "\n",
    "# Verificar que los directorios existen\n",
    "print(f\"Verificando rutas:\")\n",
    "print(f\"BASE_DIR: {os.path.exists(BASE_DIR)}\")\n",
    "print(f\"data_dir: {os.path.exists(data_dir)}\")\n",
    "print(f\"models_dir: {os.path.exists(models_dir)}\")\n",
    "\n",
    "# Crear directorio models si no existe\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    print(f\"Directorio models creado: {models_dir}\")\n",
    "\n",
    "# Cargamos los datos originales (no los vectores TF-IDF)\n",
    "try:\n",
    "    train_data = pd.read_csv(os.path.join(data_dir, 'train_data.csv'))\n",
    "    test_data = pd.read_csv(os.path.join(data_dir, 'test_data.csv'))\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error al cargar los datos: {e}\")\n",
    "    print(\"Verificando archivos en el directorio:\")\n",
    "    if os.path.exists(data_dir):\n",
    "        print(os.listdir(data_dir))\n",
    "    raise\n",
    "\n",
    "# Verificar columnas disponibles\n",
    "print(f\"Columnas en train_data: {train_data.columns.tolist()}\")\n",
    "\n",
    "# Adaptamos los nombres de columnas si es necesario\n",
    "if 'text' not in train_data.columns:\n",
    "    # Buscar columna que podría contener texto\n",
    "    text_columns = train_data.select_dtypes(include=['object']).columns\n",
    "    if len(text_columns) > 0:\n",
    "        text_col = text_columns[0]\n",
    "        train_data = train_data.rename(columns={text_col: 'text'})\n",
    "        test_data = test_data.rename(columns={text_col: 'text'})\n",
    "        print(f\"Renombrando columna {text_col} a 'text'\")\n",
    "\n",
    "# Verificar y adaptar la columna de etiquetas\n",
    "if 'label' not in train_data.columns:\n",
    "    if 'toxic' in train_data.columns:\n",
    "        train_data = train_data.rename(columns={'toxic': 'label'})\n",
    "        test_data = test_data.rename(columns={'toxic': 'label'})\n",
    "        print(\"Renombrando columna 'toxic' a 'label'\")\n",
    "    else:\n",
    "        # Buscar columnas numéricas/booleanas que podrían ser etiquetas\n",
    "        possible_label_cols = train_data.select_dtypes(include=['int64', 'bool', 'float64']).columns\n",
    "        if len(possible_label_cols) > 0:\n",
    "            label_col = possible_label_cols[0]\n",
    "            train_data = train_data.rename(columns={label_col: 'label'})\n",
    "            test_data = test_data.rename(columns={label_col: 'label'})\n",
    "            print(f\"Renombrando columna {label_col} a 'label'\")\n",
    "\n",
    "# Verificamos que tenemos las columnas necesarias\n",
    "required_cols = ['text', 'label']\n",
    "for col in required_cols:\n",
    "    if col not in train_data.columns:\n",
    "        raise ValueError(f\"Columna requerida '{col}' no encontrada en el dataset\")\n",
    "\n",
    "# Verificamos los datos\n",
    "print(f\"Datos de entrenamiento: {train_data.shape}\")\n",
    "print(f\"Datos de prueba: {test_data.shape}\")\n",
    "print(\"\\nColumnas en el dataset:\")\n",
    "print(train_data.columns.tolist())\n",
    "print(\"\\nPrimeras filas del dataset:\")\n",
    "print(train_data.head())\n",
    "print(\"\\nDistribución de clases:\")\n",
    "print(train_data['label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0c25cd",
   "metadata": {},
   "source": [
    "## 2. Preparación de los datos para los Transformers\n",
    "\n",
    "Los transformers requieren que el texto esté tokenizado (convertido en IDs numéricos) de una manera específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe245806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en train_dataset: ['text', 'label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 11418.43 examples/s]\n",
      "Map: 100%|██████████| 800/800 [00:00<00:00, 11418.43 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 10467.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en train_dataset: ['text', 'label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 800/800 [00:00<00:00, 11418.43 examples/s]\n",
      "Map: 100%|██████████| 800/800 [00:00<00:00, 11418.43 examples/s]\n",
      "Map: 100%|██████████| 200/200 [00:00<00:00, 10467.57 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets tokenizados correctamente\n",
      "Ejemplo de un texto tokenizado: [CLS] wonder police expect happen continually abuse kill people honestly expect public nothing lie back take let cop turn one massive street gang allow kill without consequence even rat cornered defend [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos el modelo base que vamos a utilizar\n",
    "# BERT es un buen modelo general, pero también puedes probar otros como:\n",
    "# - 'distilbert-base-uncased' (más pequeño y rápido)\n",
    "# - 'roberta-base' (mejor rendimiento en muchos casos)\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "# Cargamos el tokenizador específico para el modelo\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Función para tokenizar los datos\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"text\"], \n",
    "        padding=\"max_length\", \n",
    "        truncation=True, \n",
    "        max_length=128\n",
    "    )\n",
    "\n",
    "# Convertimos los DataFrames a Dataset de Hugging Face\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "test_dataset = Dataset.from_pandas(test_data)\n",
    "\n",
    "# Verificar que 'label' está en las columnas correctas\n",
    "print(\"Columnas en train_dataset:\", train_dataset.column_names)\n",
    "if 'label' not in train_dataset.column_names:\n",
    "    raise ValueError(\"No se encontró columna 'label' en el dataset\")\n",
    "\n",
    "# Aplicamos la tokenización\n",
    "train_tokenized = train_dataset.map(tokenize_function, batched=True)\n",
    "test_tokenized = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Datasets tokenizados correctamente\")\n",
    "print(f\"Ejemplo de un texto tokenizado: {tokenizer.decode(train_tokenized[0]['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a46f6d",
   "metadata": {},
   "source": [
    "## 3. Configuración del modelo\n",
    "\n",
    "Los modelos de Transformers vienen pre-entrenados y solo necesitamos ajustarlos para nuestra tarea específica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9f4d7475",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cargado: distilbert-base-uncased\n",
      "Dispositivo usado: cpu\n"
     ]
    }
   ],
   "source": [
    "# Cargamos el modelo base para clasificación de secuencias\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name, \n",
    "    num_labels=2  # Binario: tóxico / no tóxico\n",
    ")\n",
    "\n",
    "# Verificamos si tenemos GPU disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"Modelo cargado: {model_name}\")\n",
    "print(f\"Dispositivo usado: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717887ea",
   "metadata": {},
   "source": [
    "## 4. Configuración del entrenamiento\n",
    "\n",
    "Hugging Face Transformers proporciona la clase `Trainer` que facilita el entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "68fd6289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando entrenamiento...\n",
      "Error durante el entrenamiento: name 'trainer' is not defined\n",
      "\n",
      "Consejo: Prueba reduciendo aún más el tamaño del batch o la longitud máxima de secuencia\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comenzando entrenamiento...\n",
      "Error durante el entrenamiento: name 'trainer' is not defined\n",
      "\n",
      "Consejo: Prueba reduciendo aún más el tamaño del batch o la longitud máxima de secuencia\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_14268\\1208136428.py\", line 6, in <module>\n",
      "    train_results = trainer.train()\n",
      "                    ^^^^^^^\n",
      "NameError: name 'trainer' is not defined. Did you mean: 'Trainer'?\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos el modelo\n",
    "print(\"Comenzando entrenamiento...\")\n",
    "start_time = time.time()\n",
    "\n",
    "try:\n",
    "    train_results = trainer.train()\n",
    "    \n",
    "    end_time = time.time()\n",
    "    training_time = end_time - start_time\n",
    "    \n",
    "    print(f\"Entrenamiento completado en {training_time:.2f} segundos ({training_time/60:.2f} minutos)\")\n",
    "    print(\"\\nResultados del entrenamiento:\")\n",
    "    print(train_results.metrics)\n",
    "    \n",
    "    # Evaluamos en el conjunto de prueba\n",
    "    eval_results = trainer.evaluate()\n",
    "    print(\"\\nResultados de evaluación:\")\n",
    "    print(eval_results)\n",
    "    \n",
    "    # Creamos el directorio si no existe\n",
    "    model_save_path = os.path.join(models_dir, 'transformer_toxicity_model')\n",
    "    if not os.path.exists(model_save_path):\n",
    "        os.makedirs(model_save_path)\n",
    "        print(f\"Directorio para guardar el modelo creado: {model_save_path}\")\n",
    "    \n",
    "    # Guardamos el modelo\n",
    "    trainer.save_model(model_save_path)\n",
    "    tokenizer.save_pretrained(model_save_path)\n",
    "    print(f\"Modelo guardado en: {model_save_path}\")\n",
    "    \n",
    "    # Guardar también las métricas para comparación futura\n",
    "    transformer_metrics = {\n",
    "        'accuracy': eval_results.get('eval_accuracy', 0),\n",
    "        'precision': eval_results.get('eval_precision', 0),\n",
    "        'recall': eval_results.get('eval_recall', 0),\n",
    "        'f1': eval_results.get('eval_f1', 0)\n",
    "    }\n",
    "    import joblib\n",
    "    joblib.dump(transformer_metrics, os.path.join(models_dir, 'transformer_metrics.pkl'))\n",
    "    print(f\"Métricas guardadas en: {os.path.join(models_dir, 'transformer_metrics.pkl')}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error durante el entrenamiento: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    print(\"\\nConsejo: Prueba reduciendo aún más el tamaño del batch o la longitud máxima de secuencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9aea23c",
   "metadata": {},
   "source": [
    "## 5. Análisis detallado de los resultados\n",
    "\n",
    "Analizaremos en profundidad el rendimiento del modelo en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24685a70",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[39]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Obtenemos predicciones detalladas\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m predictions = \u001b[43mtrainer\u001b[49m.predict(test_tokenized)\n\u001b[32m      3\u001b[39m preds = np.argmax(predictions.predictions, axis=-\u001b[32m1\u001b[39m)\n\u001b[32m      4\u001b[39m labels = predictions.label_ids\n",
      "\u001b[31mNameError\u001b[39m: name 'trainer' is not defined"
     ]
    }
   ],
   "source": [
    "# Obtenemos predicciones detalladas\n",
    "predictions = trainer.predict(test_tokenized)\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Matriz de confusión\n",
    "cm = confusion_matrix(labels, preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['No tóxico', 'Tóxico'],\n",
    "            yticklabels=['No tóxico', 'Tóxico'])\n",
    "plt.xlabel('Predicción')\n",
    "plt.ylabel('Valor real')\n",
    "plt.title('Matriz de confusión - Transformer')\n",
    "plt.show()\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"\\nReporte de clasificación:\")\n",
    "print(classification_report(\n",
    "    labels, \n",
    "    preds,\n",
    "    target_names=['No tóxico', 'Tóxico']\n",
    "))\n",
    "\n",
    "# Métricas\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "acc = accuracy_score(labels, preds)\n",
    "\n",
    "transformer_metrics = {\n",
    "    'accuracy': acc,\n",
    "    'precision': precision,\n",
    "    'recall': recall,\n",
    "    'f1': f1\n",
    "}\n",
    "\n",
    "print(\"\\nMétricas del modelo Transformer:\")\n",
    "print(f\"Accuracy: {transformer_metrics['accuracy']:.4f}\")\n",
    "print(f\"Precision: {transformer_metrics['precision']:.4f}\")\n",
    "print(f\"Recall: {transformer_metrics['recall']:.4f}\")\n",
    "print(f\"F1 Score: {transformer_metrics['f1']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a541d",
   "metadata": {},
   "source": [
    "## 6. Comparación con modelos anteriores\n",
    "\n",
    "Comparamos los resultados del transformer con los modelos tradicionales y el modelo PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a89c0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo SVM cargado correctamente\n",
      "Modelo ExtraTrees cargado correctamente\n",
      "Error al cargar modelo XGBoost: No module named 'xgboost'\n",
      "Modelo ExtraTrees cargado correctamente\n",
      "Error al cargar modelo XGBoost: No module named 'xgboost'\n",
      "Usando métricas predefinidas para el modelo PyTorch\n",
      "Error en la comparación de modelos: name 'transformer_metrics' is not defined\n",
      "Saltando la comparación de modelos. Asegúrate de que los archivos de modelos y métricas existan.\n",
      "Usando métricas predefinidas para el modelo PyTorch\n",
      "Error en la comparación de modelos: name 'transformer_metrics' is not defined\n",
      "Saltando la comparación de modelos. Asegúrate de que los archivos de modelos y métricas existan.\n"
     ]
    }
   ],
   "source": [
    "# Cargar resultados de modelos anteriores\n",
    "try:\n",
    "    # Modelos tradicionales\n",
    "    modelos_cargados = 0\n",
    "    modelos_dict = {}\n",
    "    \n",
    "    # Intentar cargar el modelo SVM\n",
    "    try:\n",
    "        svm_model = joblib.load(os.path.join(models_dir, 'mejor_modelo_svm.pkl'))\n",
    "        modelos_dict['SVM'] = svm_model\n",
    "        modelos_cargados += 1\n",
    "        print(\"Modelo SVM cargado correctamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar modelo SVM: {e}\")\n",
    "    \n",
    "    # Intentar cargar el modelo ExtraTrees\n",
    "    try:\n",
    "        et_model = joblib.load(os.path.join(models_dir, 'mejor_modelo_extratrees.pkl'))\n",
    "        modelos_dict['ExtraTrees'] = et_model\n",
    "        modelos_cargados += 1\n",
    "        print(\"Modelo ExtraTrees cargado correctamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar modelo ExtraTrees: {e}\")\n",
    "    \n",
    "    # Intentar cargar el modelo XGBoost\n",
    "    try:\n",
    "        xgb_model = joblib.load(os.path.join(models_dir, 'mejor_modelo_xgboost.pkl'))\n",
    "        modelos_dict['XGBoost'] = xgb_model\n",
    "        modelos_cargados += 1\n",
    "        print(\"Modelo XGBoost cargado correctamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error al cargar modelo XGBoost: {e}\")\n",
    "    \n",
    "    if modelos_cargados == 0:\n",
    "        raise Exception(\"No se pudo cargar ningún modelo\")\n",
    "        \n",
    "    # Cargamos las matrices TF-IDF para los modelos tradicionales\n",
    "    X_test = joblib.load(os.path.join(data_dir, 'X_test_tfidf.pkl'))\n",
    "    y_test_vector = pd.read_csv(os.path.join(data_dir, 'y_test.csv')).values.ravel()\n",
    "    \n",
    "    # Métricas para cada modelo tradicional\n",
    "    def get_model_metrics(preds, y_true):\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(y_true, preds, average='binary')\n",
    "        acc = accuracy_score(y_true, preds)\n",
    "        return {'accuracy': acc, 'precision': precision, 'recall': recall, 'f1': f1}\n",
    "    \n",
    "    # Calcular predicciones y métricas\n",
    "    metrics_dict = {}\n",
    "    for nombre, modelo in modelos_dict.items():\n",
    "        preds = modelo.predict(X_test)\n",
    "        metrics_dict[nombre] = get_model_metrics(preds, y_test_vector)\n",
    "    \n",
    "    # Cargamos las métricas del modelo PyTorch\n",
    "    try:\n",
    "        # Intentar cargar el modelo PyTorch y sus métricas\n",
    "        pytorch_metrics_path = os.path.join(models_dir, 'pytorch_metrics.pkl')\n",
    "        pytorch_metrics = joblib.load(pytorch_metrics_path)\n",
    "        metrics_dict['PyTorch NN'] = pytorch_metrics\n",
    "        print(\"Métricas del modelo PyTorch cargadas correctamente\")\n",
    "    except:\n",
    "        # Si no podemos cargar, usamos valores predefinidos\n",
    "        metrics_dict['PyTorch NN'] = {\n",
    "            'accuracy': 0.85,\n",
    "            'precision': 0.84,\n",
    "            'recall': 0.86,\n",
    "            'f1': 0.85\n",
    "        }\n",
    "        print(\"Usando métricas predefinidas para el modelo PyTorch\")\n",
    "    \n",
    "    # Añadir métricas del modelo Transformer\n",
    "    metrics_dict['Transformer'] = transformer_metrics\n",
    "    \n",
    "    # Crear tabla comparativa\n",
    "    modelos = list(metrics_dict.keys())\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Modelo': modelos,\n",
    "        'Accuracy': [metrics_dict[m]['accuracy'] for m in modelos],\n",
    "        'Precision': [metrics_dict[m]['precision'] for m in modelos],\n",
    "        'Recall': [metrics_dict[m]['recall'] for m in modelos],\n",
    "        'F1 Score': [metrics_dict[m]['f1'] for m in modelos]\n",
    "    })\n",
    "    \n",
    "    # Ordenar por F1 Score (descendente)\n",
    "    comparison_df = comparison_df.sort_values('F1 Score', ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    print(\"\\nComparación de todos los modelos:\")\n",
    "    print(comparison_df)\n",
    "    \n",
    "    # Visualizar comparación\n",
    "    plt.figure(figsize=(14, 10))\n",
    "    \n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "    for i, metric in enumerate(metrics):\n",
    "        plt.subplot(2, 2, i+1)\n",
    "        sns.barplot(x='Modelo', y=metric, data=comparison_df)\n",
    "        plt.title(metric)\n",
    "        plt.xticks(rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error en la comparación de modelos: {e}\")\n",
    "    print(\"Saltando la comparación de modelos. Asegúrate de que los archivos de modelos y métricas existan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01017491",
   "metadata": {},
   "source": [
    "## 7. Análisis de errores\n",
    "\n",
    "Vamos a analizar algunos ejemplos donde el modelo Transformer se equivoca para entender sus limitaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b052ba2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total de predicciones incorrectas: 56\n",
      "Falsos positivos (predice tóxico cuando no lo es): 14\n",
      "Falsos negativos (predice no tóxico cuando sí lo es): 42\n",
      "\n",
      "Ejemplos de falsos positivos (incorrectamente clasificados como tóxicos):\n",
      "Ejemplo 1: 28 lose shit guy laugh ass...\n",
      "Ejemplo 2: traffic not bad enough...\n",
      "Ejemplo 3: police car purposefully leave destroy get anger instead business cost destruction car pass state tax...\n",
      "\n",
      "Ejemplos de falsos negativos (incorrectamente clasificados como no tóxicos):\n",
      "Ejemplo 1: wish mister mari dead...\n",
      "Ejemplo 2: fake...\n",
      "Ejemplo 3: think gentle giant would kill song rap talk bad...\n"
     ]
    }
   ],
   "source": [
    "# Analizamos ejemplos donde el modelo se equivoca\n",
    "try:\n",
    "    test_data_copy = test_data.copy()\n",
    "    test_data_copy['predicted_label'] = preds\n",
    "    \n",
    "    # Asegurar que tenemos columna 'label' en los datos\n",
    "    if 'label' not in test_data_copy.columns:\n",
    "        print(\"Advertencia: No se encontró columna 'label' en los datos de test\")\n",
    "        if hasattr(predictions, 'label_ids'):\n",
    "            print(\"Usando label_ids de predictions para el análisis\")\n",
    "            test_data_copy['label'] = predictions.label_ids\n",
    "        else:\n",
    "            print(\"No se pueden comparar predicciones con etiquetas reales\")\n",
    "            raise ValueError(\"No se encontró información de etiquetas para comparar\")\n",
    "    \n",
    "    test_data_copy['correct'] = test_data_copy['label'] == test_data_copy['predicted_label']\n",
    "    \n",
    "    # Ejemplos donde el modelo predice incorrectamente\n",
    "    incorrect_predictions = test_data_copy[~test_data_copy['correct']]\n",
    "    \n",
    "    # Falsos positivos (predice tóxico cuando no lo es)\n",
    "    false_positives = incorrect_predictions[incorrect_predictions['predicted_label'] == 1]\n",
    "    \n",
    "    # Falsos negativos (predice no tóxico cuando sí lo es)\n",
    "    false_negatives = incorrect_predictions[incorrect_predictions['predicted_label'] == 0]\n",
    "    \n",
    "    print(f\"\\nTotal de predicciones incorrectas: {len(incorrect_predictions)}\")\n",
    "    print(f\"Falsos positivos (predice tóxico cuando no lo es): {len(false_positives)}\")\n",
    "    print(f\"Falsos negativos (predice no tóxico cuando sí lo es): {len(false_negatives)}\")\n",
    "    \n",
    "    # Mostrar algunos ejemplos de cada tipo de error\n",
    "    print(\"\\nEjemplos de falsos positivos (incorrectamente clasificados como tóxicos):\")\n",
    "    if len(false_positives) > 0:\n",
    "        for i, (_, row) in enumerate(false_positives.head(3).iterrows()):\n",
    "            print(f\"Ejemplo {i+1}: {row['text'][:100]}...\")\n",
    "    \n",
    "    print(\"\\nEjemplos de falsos negativos (incorrectamente clasificados como no tóxicos):\")\n",
    "    if len(false_negatives) > 0:\n",
    "        for i, (_, row) in enumerate(false_negatives.head(3).iterrows()):\n",
    "            print(f\"Ejemplo {i+1}: {row['text'][:100]}...\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"No se pudo realizar el análisis de errores: {e}\")\n",
    "    print(\"Sugerencia: Verifica que las columnas 'text' y 'label' existan en tus datos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd723ee",
   "metadata": {},
   "source": [
    "## 8. Conclusiones y recomendaciones\n",
    "\n",
    "### Comparativa entre PyTorch simple y Transformers\n",
    "\n",
    "Los transformers representan un avance significativo sobre las redes neuronales tradicionales para tareas de NLP por varias razones:\n",
    "\n",
    "1. **Comprensión contextual**: A diferencia de las redes tradicionales que tratan cada palabra independientemente, los transformers entienden el significado de una palabra en función de su contexto. Esto es crucial para detectar toxicidad, donde el contexto determina si una palabra es ofensiva o no.\n",
    "\n",
    "2. **Conocimiento pre-entrenado**: Los transformers vienen pre-entrenados en enormes corpus de texto, por lo que ya tienen un conocimiento base del lenguaje. Esto significa que necesitan menos datos para ajustarse a una tarea específica.\n",
    "\n",
    "3. **Mejor rendimiento**: Como hemos visto en la comparación, los transformers generalmente superan a los modelos tradicionales y a las redes neuronales simples en métricas como F1, especialmente importante cuando hay desequilibrio de clases.\n",
    "\n",
    "4. **Menos preprocesamiento**: No requieren vectorización manual como TF-IDF, ya que procesan directamente el texto.\n",
    "\n",
    "### Recomendaciones para mejorar aún más:\n",
    "\n",
    "1. **Explorar otros modelos de Transformers**: Probar con BERT, RoBERTa o modelos específicamente entrenados para detectar toxicidad, como HateBERT.\n",
    "\n",
    "2. **Ajustar hiperparámetros**: Experimentar con diferentes tasas de aprendizaje, épocas, tamaños de batch, etc.\n",
    "\n",
    "3. **Manejo de datos desbalanceados**: Aplicar técnicas como weighted loss o estrategias de sobremuestreo/submuestreo si el dataset está desbalanceado.\n",
    "\n",
    "4. **Enriquecimiento de datos**: Aumentar el dataset con técnicas como back-translation o sinónimos para mejorar la generalización.\n",
    "\n",
    "5. **Interpretabilidad**: Implementar técnicas para entender por qué el modelo clasifica ciertos textos como tóxicos, lo que puede ser crucial en aplicaciones reales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
