{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZvQSiRFmaVOB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "X_train = joblib.load('X_train_tfidf.pkl')\n",
    "X_test = joblib.load('X_test_tfidf.pkl')\n",
    "\n",
    "# Cargar etiquetas\n",
    "y_train = pd.read_csv('y_train.csv')['IsToxic']\n",
    "y_test = pd.read_csv('y_test.csv')['IsToxic']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZogWUuDM55uO"
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3zaQJj46dxgY",
    "outputId": "1fa8a30f-ad67-4eaa-ee1a-4f4fa605b18b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76       108\n",
      "           1       0.76      0.54      0.63        92\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.72      0.70      0.70       200\n",
      "weighted avg       0.72      0.71      0.70       200\n",
      "\n",
      "\n",
      "=== Naive Bayes ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.81      0.73       108\n",
      "           1       0.70      0.50      0.58        92\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.68      0.66      0.65       200\n",
      "weighted avg       0.68      0.67      0.66       200\n",
      "\n",
      "\n",
      "=== Linear SVC ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.77      0.73       108\n",
      "           1       0.70      0.62      0.66        92\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.70      0.69      0.69       200\n",
      "weighted avg       0.70      0.70      0.70       200\n",
      "\n",
      "\n",
      "=== Random Forest ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.90      0.78       108\n",
      "           1       0.81      0.52      0.64        92\n",
      "\n",
      "    accuracy                           0.72       200\n",
      "   macro avg       0.75      0.71      0.71       200\n",
      "weighted avg       0.75      0.72      0.71       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Naive Bayes': MultinomialNB(),\n",
    "    'Linear SVC': LinearSVC(),\n",
    "    'Random Forest': RandomForestClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(f\"\\n=== {name} ===\")\n",
    "    print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFV3x-kWhaNj",
    "outputId": "8a08ada8-02fa-4cb8-f8b4-76a489602cce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validation Accuracy Scores: [0.725   0.70625 0.70625 0.69375 0.725  ]\n",
      "Mean Accuracy: 0.71125\n",
      "Standard Deviation: 0.012119199643540812\n",
      "\n",
      "Classification Report (Train):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.77      0.74       430\n",
      "           1       0.71      0.64      0.67       370\n",
      "\n",
      "    accuracy                           0.71       800\n",
      "   macro avg       0.71      0.71      0.71       800\n",
      "weighted avg       0.71      0.71      0.71       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Modelo\n",
    "model = LogisticRegression(max_iter=1000, class_weight='balanced')\n",
    "\n",
    "# === 1. Cross-Validation Scores ===\n",
    "cv_scores = cross_val_score(model, X_train, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-Validation Accuracy Scores:\", cv_scores)\n",
    "print(\"Mean Accuracy:\", np.mean(cv_scores))\n",
    "print(\"Standard Deviation:\", np.std(cv_scores))\n",
    "\n",
    "# === 2. Cross-Validated Predictions for Classification Report ===\n",
    "y_train_pred = cross_val_predict(model, X_train, y_train, cv=5)\n",
    "print(\"\\nClassification Report (Train):\")\n",
    "print(classification_report(y_train, y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2OWIncLmzyP"
   },
   "outputs": [],
   "source": [
    "X_train_text = pd.read_csv('train_data.csv')['text']\n",
    "X_test_text = pd.read_csv('test_data.csv')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gffhtpctmqvQ",
    "outputId": "2257685c-9da6-44d5-822a-c24f0dc19780"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n",
      "Mejores parámetros: {'clf__C': 0.001, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'tfidf__max_df': 0.9, 'tfidf__max_features': 3000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)}\n",
      "Mejor F1-score (validación cruzada): 0.7037745222767379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Pipeline para unir vectorización y modelo\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),  # Puedes modificar parámetros luego\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "# Parámetros para GridSearch\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],       # unigrama o unigrama+bigramas\n",
    "    'tfidf__min_df': [2, 5],                     # palabras que aparecen en al menos 2 o 5 documentos\n",
    "    'tfidf__max_df': [0.9, 0.95],                # descartar palabras muy frecuentes\n",
    "    'tfidf__max_features': [3000, 5000],         # limitar vocabulario\n",
    "\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'clf__solver': ['liblinear', 'saga'],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Entrenar GridSearch\n",
    "grid.fit(X_train_text, y_train)  # <-- si tienes el texto original para vectorizar\n",
    "\n",
    "# Resultados\n",
    "print(\"Mejores parámetros:\", grid.best_params_)\n",
    "print(\"Mejor F1-score (validación cruzada):\", grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tgCYmRfQrGrl",
    "outputId": "173c1a21-c04c-4a87-b28b-2303ad681323"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 640 candidates, totalling 3200 fits\n",
      "Mejores parámetros: {'clf__C': 0.001, 'clf__class_weight': 'balanced', 'clf__penalty': 'l2', 'clf__solver': 'liblinear', 'tfidf__max_df': 0.9, 'tfidf__max_features': 3000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)}\n",
      "Mejor F1-score (validación cruzada): 0.7037745222767379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.61      0.70       108\n",
      "           1       0.65      0.84      0.73        92\n",
      "\n",
      "    accuracy                           0.71       200\n",
      "   macro avg       0.73      0.72      0.71       200\n",
      "weighted avg       0.74      0.71      0.71       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Suponiendo que tienes X_train_text (texto crudo) y y_train (etiquetas)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],          # unigrams o unigrams + bigrams\n",
    "    'tfidf__min_df': [2, 5],                        # palabras que aparecen en al menos 2 o 5 documentos\n",
    "    'tfidf__max_df': [0.9, 0.95],                   # eliminar palabras muy comunes\n",
    "    'tfidf__max_features': [3000, 5000],            # limitar vocabulario\n",
    "\n",
    "    'clf__C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'clf__solver': ['liblinear', 'saga'],\n",
    "    'clf__penalty': ['l1', 'l2'],\n",
    "    'clf__class_weight': [None, 'balanced']\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "\n",
    "# Entrenar GridSearch\n",
    "grid.fit(X_train_text, y_train)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid.best_params_)\n",
    "print(\"Mejor F1-score (validación cruzada):\", grid.best_score_)\n",
    "\n",
    "# Para evaluar en test\n",
    "best_model = grid.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test_text)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sLE-tq5e6ACD",
    "outputId": "fe5524da-45c5-40a2-b266-d1a4b218f9a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['log_regr.pkl']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gbm, 'log_regr.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JDoL7b4652M5"
   },
   "source": [
    "## GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OUew9Y2Yt_Oi",
    "outputId": "8799a5e0-fd02-4469-dcd6-aac7151a7983"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.84      0.76       108\n",
      "           1       0.75      0.54      0.63        92\n",
      "\n",
      "    accuracy                           0.70       200\n",
      "   macro avg       0.72      0.69      0.69       200\n",
      "weighted avg       0.71      0.70      0.70       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "gbm = GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "gbm.fit(X_train, y_train)\n",
    "y_pred = gbm.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P45LD5zPuSQt",
    "outputId": "11089783-2f43-4169-a59a-83dcb22c4c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros GBM: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 200}\n",
      "Mejor F1 (GBM): 0.6292761602917867\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid_gbm = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.1, 0.05],\n",
    "    'max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "grid_gbm = GridSearchCV(GradientBoostingClassifier(), param_grid_gbm, cv=5, scoring='f1', n_jobs=-1)\n",
    "grid_gbm.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros GBM:\", grid_gbm.best_params_)\n",
    "print(\"Mejor F1 (GBM):\", grid_gbm.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BQlUN6HKsE8M",
    "outputId": "560282cc-ece8-4afd-8cc9-af5fd324db63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "Mejores parámetros: {'clf__learning_rate': 0.1, 'clf__max_depth': 5, 'clf__n_estimators': 200, 'tfidf__max_df': 0.9, 'tfidf__max_features': 5000, 'tfidf__min_df': 2, 'tfidf__ngram_range': (1, 2)}\n",
      "Mejor F1-score (validación cruzada): 0.6596075488325731\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.80      0.73       108\n",
      "           1       0.70      0.55      0.62        92\n",
      "\n",
      "    accuracy                           0.69       200\n",
      "   macro avg       0.69      0.68      0.68       200\n",
      "weighted avg       0.69      0.69      0.68       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('clf', GradientBoostingClassifier())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
    "    'tfidf__min_df': [2, 5],\n",
    "    'tfidf__max_df': [0.9, 0.95],\n",
    "    'tfidf__max_features': [3000, 5000],\n",
    "\n",
    "    'clf__n_estimators': [100, 200],\n",
    "    'clf__learning_rate': [0.1, 0.05],\n",
    "    'clf__max_depth': [3, 5]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(pipe, param_grid, cv=5, scoring='f1', n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train_text, y_train)\n",
    "\n",
    "print(\"Mejores parámetros:\", grid.best_params_)\n",
    "print(\"Mejor F1-score (validación cruzada):\", grid.best_score_)\n",
    "\n",
    "best_model = grid.best_estimator_\n",
    "y_test_pred = best_model.predict(X_test_text)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xokue3lN4_OT",
    "outputId": "f36c22b6-db40-44eb-8856-3c945293f2e9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['modelo_gbm.pkl']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(gbm, 'modelo_gbm.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
