{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7867094f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "flask 3.0.3 requires click>=8.1.3, which is not installed.\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Using cached transformers-4.53.1-py3-none-any.whl (10.8 MB)\n",
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp310-cp310-win_amd64.whl (216.1 MB)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (25.0)\n",
      "Collecting safetensors>=0.4.3\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.30.0\n",
      "  Using cached huggingface_hub-0.33.2-py3-none-any.whl (515 kB)\n",
      "Collecting requests\n",
      "  Using cached requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Collecting tokenizers<0.22,>=0.21\n",
      "  Using cached tokenizers-0.21.2-cp39-abi3-win_amd64.whl (2.5 MB)\n",
      "Collecting regex!=2019.12.17\n",
      "  Using cached regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting sympy>=1.13.3\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Collecting networkx\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from torch) (4.14.0)\n",
      "Collecting fsspec\n",
      "  Using cached fsspec-2025.5.1-py3-none-any.whl (199 kB)\n",
      "Collecting jinja2\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Collecting idna<4,>=2.5\n",
      "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Collecting charset_normalizer<4,>=2\n",
      "  Using cached charset_normalizer-3.4.2-cp310-cp310-win_amd64.whl (105 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2025.7.9-py3-none-any.whl (159 kB)\n",
      "     ---------------------------------------- 0.0/159.2 kB ? eta -:--:--\n",
      "     -------------------------------------- 159.2/159.2 kB 9.9 MB/s eta 0:00:00\n",
      "Installing collected packages: mpmath, sympy, safetensors, regex, networkx, jinja2, idna, fsspec, filelock, charset_normalizer, certifi, torch, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2025.7.9 charset_normalizer-3.4.2 filelock-3.18.0 fsspec-2025.5.1 huggingface-hub-0.33.2 idna-3.10 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 regex-2024.11.6 requests-2.32.4 safetensors-0.5.3 sympy-1.14.0 tokenizers-0.21.2 torch-2.7.1 transformers-4.53.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(probs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m id2label \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mid2label\n\u001b[1;32m---> 27\u001b[0m labels \u001b[38;5;241m=\u001b[39m [id2label[\u001b[38;5;28mstr\u001b[39m(i)] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mtolist()]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, label, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(texts, labels, probs\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexto: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPredicción: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (confianza: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprob\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 27\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     24\u001b[0m     preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(probs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     26\u001b[0m id2label \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mid2label\n\u001b[1;32m---> 27\u001b[0m labels \u001b[38;5;241m=\u001b[39m [\u001b[43mid2label\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m preds\u001b[38;5;241m.\u001b[39mtolist()]\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text, label, prob \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(texts, labels, probs\u001b[38;5;241m.\u001b[39mmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mtolist()):\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTexto: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPredicción: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (confianza: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprob\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: '4'"
     ]
    }
   ],
   "source": [
    "# Prueba de modelo de sentimientos de reseñas local\n",
    "!pip install transformers torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar modelo y tokenizador locales\n",
    "model_dir = \"C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/tokenizador\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Ejemplo 1: Probar textos manualmente\n",
    "texts = [\n",
    "    \"Me encantó el producto, llegó rápido y funciona perfecto.\",\n",
    "    \"No me gustó, vino roto y el soporte no respondió.\",\n",
    "    \"Es aceptable, cumple con lo que promete.\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "id2label = model.config.id2label\n",
    "labels = [id2label[str(i)] for i in preds.tolist()]\n",
    "\n",
    "for text, label, prob in zip(texts, labels, probs.max(dim=1).values.tolist()):\n",
    "    print(f\"Texto: {text}\\nPredicción: {label} (confianza: {prob:.2f})\\n\")\n",
    "\n",
    "# Ejemplo 2: Probar con un CSV\n",
    "# Descomenta y ajusta el nombre del archivo y la columna de texto si es necesario\n",
    "# df = pd.read_csv(\"ruta/a/tu_archivo.csv\")\n",
    "# texts = df[\"Text_clean\"].astype(str).tolist()\n",
    "# inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)\n",
    "#     probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "#     preds = torch.argmax(probs, dim=1)\n",
    "# labels = [id2label[str(i)] for i in preds.tolist()]\n",
    "# df[\"sentiment_label\"] = labels\n",
    "# df[\"sentiment_score\"] = probs.max(dim=1).values.tolist()\n",
    "# df.to_csv(\"resultados_sentimiento.csv\", index=False)\n",
    "# print(\"Resultados guardados en resultados_sentimiento.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1336f8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados guardados en resultados_sentimiento.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Cargar modelo y tokenizador locales\n",
    "model_dir = \"C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/tokenizador\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Leer el CSV con la ruta correcta\n",
    "df = pd.read_csv(\"C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/data/clean/dataset_pretraining_final.csv\")\n",
    "texts = df[\"Text_clean\"].astype(str).tolist()\n",
    "\n",
    "# Procesar en lotes\n",
    "batch_size = 64\n",
    "all_labels = []\n",
    "all_scores = []\n",
    "\n",
    "id2label = model.config.id2label\n",
    "\n",
    "# Detecta el tipo de las claves del id2label (int o str)\n",
    "first_key = list(id2label.keys())[0]\n",
    "use_int = isinstance(first_key, int)\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch_texts = texts[i:i+batch_size]\n",
    "    inputs = tokenizer(batch_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "        preds = torch.argmax(probs, dim=1)\n",
    "    if use_int:\n",
    "        labels = [id2label[i] for i in preds.tolist()]\n",
    "    else:\n",
    "        labels = [id2label[str(i)] for i in preds.tolist()]\n",
    "    scores = probs.max(dim=1).values.tolist()\n",
    "    all_labels.extend(labels)\n",
    "    all_scores.extend(scores)\n",
    "\n",
    "df[\"sentiment_label\"] = all_labels\n",
    "df[\"sentiment_score\"] = all_scores\n",
    "df.to_csv(\"resultados_sentimiento.csv\", index=False)\n",
    "print(\"Resultados guardados en resultados_sentimiento.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7439e5a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Text_clean sentiment_label  \\\n",
      "0   people step case wasn people situation lump me...          1 star   \n",
      "1   La gente pasa el caso no era la situación de l...          1 star   \n",
      "2   Les personnes étapes de l'étape n'étaient pas ...          1 star   \n",
      "3   law enforcement train shoot apprehend train sh...          1 star   \n",
      "4   Sesga de trenes de la ley Trawend Train Shoot ...          1 star   \n",
      "5   Le tournage du train d'application de la loi a...          1 star   \n",
      "6   Strafverfolgung Zug Dreh Shooting Zug Shoot Tö...          1 star   \n",
      "7   reckon black life matter banner hold white cun...          1 star   \n",
      "8   Reckon Black Life Matter Banner sostenga el co...         3 stars   \n",
      "9   Reckon Black Life Matter Banner Host White Cun...         2 stars   \n",
      "10  reckon schwarzes Leben Materie Banner Halten S...         5 stars   \n",
      "11  large number people like police officer call c...          1 star   \n",
      "12  Gran número de personas como el oficial de pol...          1 star   \n",
      "13  un grand nombre de personnes comme un policier...          1 star   \n",
      "14  große Anzahl Personen wie Polizisten rufen kri...         5 stars   \n",
      "15  arab dude absolutely right shoot extra time sh...          1 star   \n",
      "16  Dude árabe absolutamente correcto disparar tie...          1 star   \n",
      "17  Dec arabe absolument droit tir supplémentaire ...          1 star   \n",
      "18  Araber Typ absolut rechts Schießen Sie zusätzl...          1 star   \n",
      "19  people facebook tie isis terrorist group musli...          1 star   \n",
      "20  Les gens Facebook attachent l'extrémiste musul...          1 star   \n",
      "21  Menschen Facebook binden isis terroristische G...          1 star   \n",
      "22  check tube post black man go epic rant ferguso...          1 star   \n",
      "23  Compruebe el tubo post negro go go rant fergus...          1 star   \n",
      "24  Vérifiez le tube post noir go epic rant Fergus...          1 star   \n",
      "25  Check Tube Post Black Man Go Epic Rant Ferguso...          1 star   \n",
      "26  love pussy staten island spit cop love happen ...          1 star   \n",
      "27  Love Pussy Staten Island Spit Cop Hubo Mike Br...          1 star   \n",
      "28  Love Pussy Staten Island Spit Cop Love Happen ...         5 stars   \n",
      "29                                    agree protestor          1 star   \n",
      "30                            Acuerde el manifestante          1 star   \n",
      "31                        Convention de manifestation         5 stars   \n",
      "32                             Protestierer zustimmen         4 stars   \n",
      "33                        mike browns father boooshit         5 stars   \n",
      "34                         Mike Browns padre boooshit         5 stars   \n",
      "35                          Mike Browns Père Boooshit         5 stars   \n",
      "36                         Mike Browns Vater Boooshit         5 stars   \n",
      "37  guy right point judge speak ability judge mess...          1 star   \n",
      "38  Guy Punto correcto Juez hablar habilidad Juez ...         3 stars   \n",
      "39  Guy Right Point Judge Speak Capacité juge Mess...          1 star   \n",
      "40  Guy richtiger Punkt Richter Speak -Fähigkeit R...          1 star   \n",
      "41  moral story reach cops gun probably gunna shoo...          1 star   \n",
      "42  Historia moral Reach Cops Gun probablemente Gu...          1 star   \n",
      "43  l'histoire morale atteint le pistolet flics pr...          1 star   \n",
      "44  Moralische Geschichte Erreicht Polizisten Waff...         3 stars   \n",
      "45                           masri close isis america         5 stars   \n",
      "46                       Masri schließen Isis America          1 star   \n",
      "47             know chimper compassion mud pump heart         5 stars   \n",
      "48  Conozca el corazón de la bomba de barro compas...         5 stars   \n",
      "49  Connaître le cœur de la pompe à boue de la com...         5 stars   \n",
      "\n",
      "    sentiment_score  \n",
      "0          0.752821  \n",
      "1          0.378387  \n",
      "2          0.451781  \n",
      "3          0.797263  \n",
      "4          0.268945  \n",
      "5          0.249266  \n",
      "6          0.711865  \n",
      "7          0.509213  \n",
      "8          0.423279  \n",
      "9          0.292414  \n",
      "10         0.394387  \n",
      "11         0.373547  \n",
      "12         0.394203  \n",
      "13         0.243482  \n",
      "14         0.362253  \n",
      "15         0.811027  \n",
      "16         0.347938  \n",
      "17         0.660074  \n",
      "18         0.502924  \n",
      "19         0.690599  \n",
      "20         0.313855  \n",
      "21         0.570493  \n",
      "22         0.654311  \n",
      "23         0.308906  \n",
      "24         0.541599  \n",
      "25         0.425557  \n",
      "26         0.631579  \n",
      "27         0.712136  \n",
      "28         0.469702  \n",
      "29         0.447004  \n",
      "30         0.419715  \n",
      "31         0.364903  \n",
      "32         0.295190  \n",
      "33         0.266722  \n",
      "34         0.315567  \n",
      "35         0.344841  \n",
      "36         0.318346  \n",
      "37         0.694380  \n",
      "38         0.373546  \n",
      "39         0.748298  \n",
      "40         0.405367  \n",
      "41         0.630947  \n",
      "42         0.509440  \n",
      "43         0.499602  \n",
      "44         0.237433  \n",
      "45         0.361132  \n",
      "46         0.264630  \n",
      "47         0.320762  \n",
      "48         0.523381  \n",
      "49         0.621495  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"resultados_sentimiento.csv\")\n",
    "print(df[[\"Text_clean\", \"sentiment_label\", \"sentiment_score\"]].head(50))  # Muestra las primeras 10 filas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e07d578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment_label\n",
      "1 star     2078\n",
      "5 stars     945\n",
      "4 stars     297\n",
      "3 stars     252\n",
      "2 stars      71\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"sentiment_label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38a0f4cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Text_clean', 'Idioma_Tecnica', 'Texto_Original', 'IsToxic',\n",
      "       'IsAbusive', 'IsThreat', 'IsProvocative', 'IsObscene', 'IsHatespeech',\n",
      "       'IsRacist', 'IsNationalist', 'IsSexist', 'IsReligiousHate',\n",
      "       'sentiment_label', 'sentiment_score'],\n",
      "      dtype='object')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      1955\n",
      "           1       0.53      0.66      0.59      1688\n",
      "           2       0.00      0.00      0.00         0\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           5       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.30      3643\n",
      "   macro avg       0.09      0.11      0.10      3643\n",
      "weighted avg       0.25      0.30      0.27      3643\n",
      "\n",
      "F1 Score: 0.2731403929199365\n",
      "Accuracy: 0.3046939335712325\n",
      "Precision: 0.2475088353552649\n",
      "Recall: 0.3046939335712325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, precision_score, recall_score\n",
    "import pandas as pd\n",
    "\n",
    "# Carga el archivo con las predicciones\n",
    "df = pd.read_csv(\"resultados_sentimiento.csv\")\n",
    "\n",
    "# Verifica que tienes la columna de etiquetas reales (por ejemplo, 'IsToxic')\n",
    "print(df.columns)  # Esto te muestra todas las columnas disponibles\n",
    "\n",
    "# Si tienes la columna 'IsToxic' (o la columna real de tu dataset), ejecuta lo siguiente:\n",
    "if \"IsToxic\" in df.columns:\n",
    "    y_true = df[\"IsToxic\"]\n",
    "    # Si tus predicciones son números (0, 1, 2, ...), usa directamente:\n",
    "    try:\n",
    "        y_pred = df[\"sentiment_label\"].astype(int)\n",
    "    except:\n",
    "        # Si tus predicciones son texto (ej: '1 star', '2 stars'), mapea a número:\n",
    "        label_map = {'1 star': 1, '2 stars': 2, '3 stars': 3, '4 stars': 4, '5 stars': 5}\n",
    "        y_pred = df[\"sentiment_label\"].map(label_map)\n",
    "    \n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y_true, y_pred, average=\"weighted\"))\n",
    "    print(\"Accuracy:\", accuracy_score(y_true, y_pred))\n",
    "    print(\"Precision:\", precision_score(y_true, y_pred, average=\"weighted\"))\n",
    "    print(\"Recall:\", recall_score(y_true, y_pred, average=\"weighted\"))\n",
    "else:\n",
    "    print(\"No hay columna de etiquetas reales para comparar métricas.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f50ba417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: maldito\n",
      "Predicción: 1 star (confianza: 0.84)\n",
      "\n",
      "Texto: fuck you\n",
      "Predicción: 1 star (confianza: 0.82)\n",
      "\n",
      "Texto: ok\n",
      "Predicción: 3 stars (confianza: 0.50)\n",
      "\n",
      "Texto: nice\n",
      "Predicción: 4 stars (confianza: 0.44)\n",
      "\n",
      "Texto: suck mi dick\n",
      "Predicción: 1 star (confianza: 0.36)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Cargar modelo y tokenizador locales\n",
    "model_dir = \"C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/tokenizador\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Escribe aquí tus frases para probar\n",
    "texts = [\n",
    "    \"maldito\",\n",
    "    \"fuck you\",\n",
    "    \"ok\",\n",
    "    \"nice\",\n",
    "    \"suck mi dick\",\n",
    "]\n",
    "\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "id2label = model.config.id2label\n",
    "# Si las claves son string\n",
    "try:\n",
    "    labels = [id2label[str(i)] for i in preds.tolist()]\n",
    "except:\n",
    "    labels = [id2label[i] for i in preds.tolist()]\n",
    "\n",
    "for text, label, prob in zip(texts, labels, probs.max(dim=1).values.tolist()):\n",
    "    print(f\"Texto: {text}\\nPredicción: {label} (confianza: {prob:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f2d85ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto: MALDITO\n",
      "Predicción: 1 star (TOXICO) (confianza: 0.84)\n",
      "\n",
      "Texto: FUCK YOU\n",
      "Predicción: 1 star (TOXICO) (confianza: 0.82)\n",
      "\n",
      "Texto: NICE\n",
      "Predicción: 4 stars (NO TOXICO) (confianza: 0.44)\n",
      "\n",
      "Texto: LOVE YOU\n",
      "Predicción: 5 stars (NO TOXICO) (confianza: 0.84)\n",
      "\n",
      "Texto: SUCK MY DICK\n",
      "Predicción: 1 star (TOXICO) (confianza: 0.63)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "# Cargar modelo y tokenizador locales\n",
    "model_dir = \"C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/tokenizador\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "\n",
    "# Escribe aquí tus frases para probar\n",
    "texts = [\n",
    "    \"MALDITO\",\n",
    "    \"FUCK YOU\",\n",
    "    \"NICE\",\n",
    "    \"LOVE YOU\",\n",
    "    \"SUCK MY DICK\"\n",
    "]\n",
    "\n",
    "inputs = tokenizer(texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    probs = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
    "    preds = torch.argmax(probs, dim=1)\n",
    "\n",
    "id2label = model.config.id2label\n",
    "# Obtener las etiquetas de estrellas\n",
    "try:\n",
    "    labels = [id2label[str(i)] for i in preds.tolist()]\n",
    "except:\n",
    "    labels = [id2label[i] for i in preds.tolist()]\n",
    "\n",
    "# Clasificar TOXICO/NO TOXICO según la estrella\n",
    "toxic_pred = [\"TOXICO\" if int(label[0]) <= 3 else \"NO TOXICO\" for label in labels]\n",
    "\n",
    "for text, label, toxic, prob in zip(texts, labels, toxic_pred, probs.max(dim=1).values.tolist()):\n",
    "    print(f\"Texto: {text}\\nPredicción: {label} ({toxic}) (confianza: {prob:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "08dc5b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers and GPU quantization are unavailable.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m bnb_config \u001b[38;5;241m=\u001b[39m BitsAndBytesConfig(load_in_8bit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# Carga el modelo en int8\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquantization_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbnb_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Usa \"auto\" si tienes GPU con soporte\u001b[39;49;00m\n\u001b[0;32m     30\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(model_dir)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Guarda el modelo cuantizado\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:600\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mconfig_class \u001b[38;5;241m==\u001b[39m config\u001b[38;5;241m.\u001b[39msub_configs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext_config\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    599\u001b[0m         config \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget_text_config()\n\u001b[1;32m--> 600\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    601\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    602\u001b[0m     )\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    605\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    606\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:311\u001b[0m, in \u001b[0;36mrestore_default_torch_dtype.<locals>._wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m old_dtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_default_dtype()\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    313\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_default_dtype(old_dtype)\n",
      "File \u001b[1;32mc:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\modeling_utils.py:4546\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   4544\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDeepSpeed Zero-3 is not compatible with passing a `device_map`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4545\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_accelerate_available():\n\u001b[1;32m-> 4546\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   4547\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4548\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires `accelerate`. You can install it with `pip install accelerate`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4549\u001b[0m         )\n\u001b[0;32m   4551\u001b[0m \u001b[38;5;66;03m# handling bnb config from kwargs, remove after `load_in_{4/8}bit` deprecation.\u001b[39;00m\n\u001b[0;32m   4552\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_in_4bit \u001b[38;5;129;01mor\u001b[39;00m load_in_8bit:\n",
      "\u001b[1;31mValueError\u001b[0m: Using a `device_map`, `tp_plan`, `torch.device` context manager or setting `torch.set_default_device(device)` requires `accelerate`. You can install it with `pip install accelerate`"
     ]
    }
   ],
   "source": [
    "# Instala dependencias solo si es necesario\n",
    "try:\n",
    "    import bitsandbytes\n",
    "except ImportError:\n",
    "    !pip install --quiet bitsandbytes\n",
    "\n",
    "try:\n",
    "    import accelerate\n",
    "except ImportError:\n",
    "    !pip install --quiet accelerate\n",
    "\n",
    "try:\n",
    "    import transformers\n",
    "except ImportError:\n",
    "    !pip install --quiet transformers\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# Ruta de tu modelo original\n",
    "model_dir = \"C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/tokenizador\"\n",
    "\n",
    "# Configuración para cargar en int8\n",
    "bnb_config = BitsAndBytesConfig(load_in_8bit=True)\n",
    "\n",
    "# Carga el modelo en int8\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_dir,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"cpu\"  # Usa \"auto\" si tienes GPU con soporte\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "# Guarda el modelo cuantizado\n",
    "output_dir = \"C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/tokenizador_int8\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Modelo cuantizado a int8 guardado en {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85ff55f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.46.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.53.1)\n",
      "Requirement already satisfied: accelerate in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.8.1)\n",
      "Requirement already satisfied: torch<3,>=2.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bitsandbytes) (2.7.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from bitsandbytes) (2.1.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.5.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.4.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch<3,>=2.2->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.7.9)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sympy>=1.13.3->torch<3,>=2.2->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from jinja2->torch<3,>=2.2->bitsandbytes) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade bitsandbytes transformers accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf0053f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo cuantizado a float16 guardado en C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/tokenizador_fp16\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_dir = \"C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/tokenizador\"\n",
    "output_dir = \"C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/tokenizador_fp16\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_dir)\n",
    "model = model.half()  # Convierte a float16\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_dir)\n",
    "\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(f\"Modelo cuantizado a float16 guardado en {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e64ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\admin\\.cache\\huggingface\\hub\\models--distilbert-base-multilingual-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "model_name = \"distilbert-base-multilingual-cased\"  # Modelo multilingüe liviano\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4744457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.0.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.33.2)\n",
      "Requirement already satisfied: fsspec[http]<=2025.3.0,>=2023.1.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2025.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.1.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: xxhash in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: requests>=2.32.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (2.32.4)\n",
      "Requirement already satisfied: packaging in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from datasets) (25.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.13)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.14.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.7.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (5.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.53.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.33.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.1.3)\n",
      "Requirement already satisfied: requests in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.4)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\admin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.7.9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 3643/3643 [00:00<00:00, 11130.14 examples/s]\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1230' max='1230' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1230/1230 55:53, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.527300</td>\n",
       "      <td>0.550048</td>\n",
       "      <td>0.717808</td>\n",
       "      <td>0.657807</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.618750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.448300</td>\n",
       "      <td>0.577449</td>\n",
       "      <td>0.761644</td>\n",
       "      <td>0.735562</td>\n",
       "      <td>0.715976</td>\n",
       "      <td>0.756250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.765375</td>\n",
       "      <td>0.764384</td>\n",
       "      <td>0.739394</td>\n",
       "      <td>0.717647</td>\n",
       "      <td>0.762500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='456' max='410' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [410/410 04:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train metrics: {'eval_loss': 0.13496804237365723, 'eval_accuracy': 0.9545454545454546, 'eval_f1': 0.9510029595527787, 'eval_precision': 0.9557171183079973, 'eval_recall': 0.9463350785340314, 'eval_runtime': 231.486, 'eval_samples_per_second': 14.161, 'eval_steps_per_second': 1.771, 'epoch': 3.0}\n",
      "Test metrics: {'eval_loss': 0.7653748393058777, 'eval_accuracy': 0.7643835616438356, 'eval_f1': 0.7393939393939394, 'eval_precision': 0.7176470588235294, 'eval_recall': 0.7625, 'eval_runtime': 26.9557, 'eval_samples_per_second': 13.541, 'eval_steps_per_second': 1.707, 'epoch': 3.0}\n",
      "Diferencia accuracy (train-test): 0.190161892901619\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('distilbert_multilingual_toxic_finetuned\\\\tokenizer_config.json',\n",
       " 'distilbert_multilingual_toxic_finetuned\\\\special_tokens_map.json',\n",
       " 'distilbert_multilingual_toxic_finetuned\\\\vocab.txt',\n",
       " 'distilbert_multilingual_toxic_finetuned\\\\added_tokens.json',\n",
       " 'distilbert_multilingual_toxic_finetuned\\\\tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pip install datasets\n",
    "!pip install --upgrade transformers\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "# 1. Carga tu dataset\n",
    "df = pd.read_csv(\"C:/Users/admin/Desktop/Proyecto 10/nlp_grupo_5_proyecto_10/data/clean/dataset_pretraining_final.csv\")\n",
    "df = df[[\"Text_clean\", \"IsToxic\"]].dropna()\n",
    "df[\"label\"] = df[\"IsToxic\"].astype(int)  # 0: NO TOXICO, 1: TOXICO\n",
    "\n",
    "# 2. Convierte a Hugging Face Dataset\n",
    "dataset = Dataset.from_pandas(df[[\"Text_clean\", \"label\"]].rename(columns={\"Text_clean\": \"text\"}))\n",
    "\n",
    "# 3. Tokeniza\n",
    "model_name = \"distilbert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "def preprocess(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "dataset = dataset.map(preprocess, batched=True)\n",
    "\n",
    "# 4. Divide en train/test\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)\n",
    "train_dataset = dataset[\"train\"]\n",
    "eval_dataset = dataset[\"test\"]\n",
    "\n",
    "# 5. Carga el modelo para clasificación binaria\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "# 6. Función de métricas personalizada\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc,\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall\n",
    "    }\n",
    "\n",
    "# 7. Configura el entrenamiento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# 8. Entrena\n",
    "trainer.train()\n",
    "\n",
    "# 9. Evalúa en train y test\n",
    "train_metrics = trainer.evaluate(train_dataset)\n",
    "test_metrics = trainer.evaluate(eval_dataset)\n",
    "\n",
    "print(\"Train metrics:\", train_metrics)\n",
    "print(\"Test metrics:\", test_metrics)\n",
    "print(\"Diferencia accuracy (train-test):\", train_metrics['eval_accuracy'] - test_metrics['eval_accuracy'])\n",
    "\n",
    "# 10. Guarda el modelo afinado\n",
    "model.save_pretrained(\"distilbert_multilingual_toxic_finetuned\")\n",
    "tokenizer.save_pretrained(\"distilbert_multilingual_toxic_finetuned\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
