{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías mágicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, classification_report\n",
    "import optuna\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/fintihlupik/NLP-sentimental/refs/heads/master/data/youtoxic_english_1000%20-%20youtoxic_english_1000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir directorios\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "data_dir = os.path.join(BASE_DIR, 'processed')  # Corregido\n",
    "models_dir = os.path.join(BASE_DIR, 'models')\n",
    "\n",
    "# Cargar datos vectorizados\n",
    "X_train = joblib.load(os.path.join(data_dir, 'X_train_tfidf.pkl'))\n",
    "X_test = joblib.load(os.path.join(data_dir, 'X_test_tfidf.pkl'))\n",
    "\n",
    "# Cargar etiquetas\n",
    "y_train = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))['IsToxic']\n",
    "y_test = pd.read_csv(os.path.join(data_dir, 'y_test.csv'))['IsToxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score inicial: 0.7077\n",
      "Reporte de clasificación inicial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.42      0.56       430\n",
      "           1       0.58      0.92      0.71       370\n",
      "\n",
      "    accuracy                           0.65       800\n",
      "   macro avg       0.72      0.67      0.64       800\n",
      "weighted avg       0.73      0.65      0.63       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, classification_report\n",
    "\n",
    "# Configuración de validación cruzada estratificada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Modelo inicial con Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Evaluación inicial con validación cruzada\n",
    "y_pred_proba = cross_val_predict(nb_model, X_train, y_train, cv=skf, method='predict_proba')[:, 1]\n",
    "\n",
    "# Calcular métricas de evaluación\n",
    "precision, recall, thresholds = precision_recall_curve(y_train, y_pred_proba)\n",
    "f1_scores = 2 * recall * precision / (recall + precision + 1e-6)\n",
    "\n",
    "# Imprimir resultados iniciales\n",
    "print(f\"F1-Score inicial: {max(f1_scores):.4f}\")\n",
    "\n",
    "# Reporte de clasificación inicial\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "print(\"Reporte de clasificación inicial:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-08 11:31:57,294] A new study created in memory with name: no-name-27165e6e-2862-4473-bde2-c70415ff8f71\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:31:57,351] Trial 0 finished with value: 0.7064671648601302 and parameters: {'alpha': 1.8515862591858971}. Best is trial 0 with value: 0.7064671648601302.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:31:57,912] Trial 1 finished with value: 0.7098316406446624 and parameters: {'alpha': 0.7358675910750551}. Best is trial 1 with value: 0.7098316406446624.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:31:58,481] Trial 2 finished with value: 0.7113767519814103 and parameters: {'alpha': 0.11882401868704891}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:31:58,613] Trial 3 finished with value: 0.7096769302282037 and parameters: {'alpha': 0.05014260017189884}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:31:59,809] Trial 4 finished with value: 0.6951359250209992 and parameters: {'alpha': 0.0047783550267410605}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:31:59,912] Trial 5 finished with value: 0.7130237993463601 and parameters: {'alpha': 0.2460081775835382}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:00,463] Trial 6 finished with value: 0.7121029162625372 and parameters: {'alpha': 0.42917986423149523}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:00,857] Trial 7 finished with value: 0.7041279518246802 and parameters: {'alpha': 2.3603980230636346}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:00,961] Trial 8 finished with value: 0.6819742529869408 and parameters: {'alpha': 0.0017910950474715462}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:01,080] Trial 9 finished with value: 0.7064671648601302 and parameters: {'alpha': 1.825623795188667}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:01,720] Trial 10 finished with value: 0.7122636590538286 and parameters: {'alpha': 0.023011571445041113}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:01,866] Trial 11 finished with value: 0.7122636590538286 and parameters: {'alpha': 0.02253758257476594}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:01,973] Trial 12 finished with value: 0.707691815412968 and parameters: {'alpha': 0.015220923040938344}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:02,636] Trial 13 finished with value: 0.7097476011947096 and parameters: {'alpha': 0.16225442766748605}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:02,802] Trial 14 finished with value: 0.7073469501514792 and parameters: {'alpha': 8.397763555867042}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:02,945] Trial 15 finished with value: 0.7015452860464862 and parameters: {'alpha': 0.007541041231425884}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:03,104] Trial 16 finished with value: 0.7109106501538774 and parameters: {'alpha': 0.31192005290492003}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:03,756] Trial 17 finished with value: 0.7094510845821145 and parameters: {'alpha': 0.04984034845135803}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:03,907] Trial 18 finished with value: 0.6802390274305277 and parameters: {'alpha': 0.0010450259708451035}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:04,028] Trial 19 finished with value: 0.70804548817579 and parameters: {'alpha': 0.03998371463109019}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:04,199] Trial 20 finished with value: 0.6916759448828338 and parameters: {'alpha': 0.003762843595663887}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:04,967] Trial 21 finished with value: 0.7092193660058521 and parameters: {'alpha': 0.017995895561159814}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:05,147] Trial 22 finished with value: 0.7097527399993185 and parameters: {'alpha': 0.024286454561346895}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:05,251] Trial 23 finished with value: 0.7096769260704374 and parameters: {'alpha': 0.0777904318435119}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:05,917] Trial 24 finished with value: 0.7028296967896822 and parameters: {'alpha': 0.010406703064604648}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:06,129] Trial 25 finished with value: 0.7119381816985422 and parameters: {'alpha': 0.19798207155965034}. Best is trial 5 with value: 0.7130237993463601.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:06,257] Trial 26 finished with value: 0.7151510204594791 and parameters: {'alpha': 0.6004815038030654}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:06,791] Trial 27 finished with value: 0.7141128953892959 and parameters: {'alpha': 0.6349971280855048}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:06,914] Trial 28 finished with value: 0.7103025356109967 and parameters: {'alpha': 0.8773009983674598}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:07,015] Trial 29 finished with value: 0.7044020181167234 and parameters: {'alpha': 3.9621030234284556}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:07,110] Trial 30 finished with value: 0.7082289294224295 and parameters: {'alpha': 1.2841651609641724}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:07,259] Trial 31 finished with value: 0.7121029162625372 and parameters: {'alpha': 0.4274523341079496}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:08,011] Trial 32 finished with value: 0.712588580972012 and parameters: {'alpha': 0.670564500074766}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:08,154] Trial 33 finished with value: 0.711216690609304 and parameters: {'alpha': 0.6853268739236964}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:08,737] Trial 34 finished with value: 0.7102036116204693 and parameters: {'alpha': 0.3576606306821281}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:08,861] Trial 35 finished with value: 0.7098316406446624 and parameters: {'alpha': 0.7302074301684413}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:08,986] Trial 36 finished with value: 0.7135011641593245 and parameters: {'alpha': 0.21986448077831047}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:09,168] Trial 37 finished with value: 0.7113767519814103 and parameters: {'alpha': 0.09083426195789167}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:09,787] Trial 38 finished with value: 0.7135011641593245 and parameters: {'alpha': 0.21192530924732075}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:09,925] Trial 39 finished with value: 0.7107838180631101 and parameters: {'alpha': 0.14362070639461919}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:10,087] Trial 40 finished with value: 0.7027702831694609 and parameters: {'alpha': 3.610521095965645}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:10,172] Trial 41 finished with value: 0.7130237993463601 and parameters: {'alpha': 0.24567532309857773}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:10,722] Trial 42 finished with value: 0.7073469501514792 and parameters: {'alpha': 1.3337039022863502}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:10,840] Trial 43 finished with value: 0.7115379676524324 and parameters: {'alpha': 0.09498863568455332}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:10,942] Trial 44 finished with value: 0.7130237993463601 and parameters: {'alpha': 0.25557678321796595}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:11,064] Trial 45 finished with value: 0.711305774477657 and parameters: {'alpha': 0.13474980228185746}. Best is trial 26 with value: 0.7151510204594791.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:11,191] Trial 46 finished with value: 0.7177028558758916 and parameters: {'alpha': 0.5090755403804245}. Best is trial 46 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:11,338] Trial 47 finished with value: 0.7177028558758916 and parameters: {'alpha': 0.4969584585168959}. Best is trial 46 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:12,002] Trial 48 finished with value: 0.7049995028128506 and parameters: {'alpha': 2.171371764612465}. Best is trial 46 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_3596\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-08 11:32:12,165] Trial 49 finished with value: 0.7177028558758916 and parameters: {'alpha': 0.49813784417239915}. Best is trial 46 with value: 0.7177028558758916.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de alpha: 0.5090755403804245\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Definir función objetivo para Optuna\n",
    "def objective(trial):\n",
    "    # Sugerir un valor para el hiperparámetro alpha\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
    "    \n",
    "    # Crear el modelo con el valor de alpha sugerido\n",
    "    model = MultinomialNB(alpha=alpha)\n",
    "    \n",
    "    # Validación cruzada estratificada\n",
    "    y_pred_proba = cross_val_predict(model, X_train, y_train, cv=skf, method='predict_proba')[:, 1]\n",
    "    \n",
    "    # Calcular F1-score\n",
    "    precision, recall, thresholds = precision_recall_curve(y_train, y_pred_proba)\n",
    "    f1_scores = 2 * recall * precision / (recall + precision + 1e-6)\n",
    "    \n",
    "    # Retornar el mejor F1-score\n",
    "    return max(f1_scores)\n",
    "\n",
    "# Crear un estudio de Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # Ejecutar 50 pruebas\n",
    "\n",
    "# Obtener el mejor hiperparámetro\n",
    "best_alpha = study.best_params['alpha']\n",
    "print(f\"Mejor valor de alpha: {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor umbral para F1-score: 0.4873\n",
      "Reporte de clasificación con umbral optimizado:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       430\n",
      "           1       0.96      0.98      0.97       370\n",
      "\n",
      "    accuracy                           0.97       800\n",
      "   macro avg       0.97      0.97      0.97       800\n",
      "weighted avg       0.97      0.97      0.97       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo con el mejor valor de alpha encontrado por Optuna\n",
    "best_model = MultinomialNB(alpha=best_alpha)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener las probabilidades predichas en el conjunto de entrenamiento\n",
    "y_pred_proba = best_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Calcular precisión, recall y F1-score para diferentes umbrales\n",
    "precision, recall, thresholds = precision_recall_curve(y_train, y_pred_proba)\n",
    "f1_scores = 2 * recall * precision / (recall + precision + 1e-6)\n",
    "\n",
    "# Encontrar el umbral que maximiza el F1-score\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Mejor umbral para F1-score: {optimal_threshold:.4f}\")\n",
    "\n",
    "# Evaluar el modelo con el umbral óptimo\n",
    "y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "print(\"Reporte de clasificación con umbral optimizado:\")\n",
    "print(classification_report(y_train, y_pred_optimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de métricas:\n",
      "Modelo                        F1-Score       Accuracy       \n",
      "Modelo inicial (umbral 0.5)   0.9392         0.9450         \n",
      "Modelo optimizado (umbral 0.5)0.9622         0.9650         \n",
      "Modelo optimizado (mejor umbral)0.9665         0.9688         \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Evaluación con el modelo inicial (umbral predeterminado de 0.5)\n",
    "initial_model = MultinomialNB()\n",
    "initial_model.fit(X_train, y_train)\n",
    "y_pred_initial = initial_model.predict(X_train)\n",
    "initial_f1 = f1_score(y_train, y_pred_initial)\n",
    "initial_accuracy = accuracy_score(y_train, y_pred_initial)\n",
    "\n",
    "# 2. Evaluación con el modelo optimizado (mejor alpha, umbral predeterminado de 0.5)\n",
    "optimized_model = MultinomialNB(alpha=best_alpha)\n",
    "optimized_model.fit(X_train, y_train)\n",
    "y_pred_optimized = optimized_model.predict(X_train)\n",
    "optimized_f1 = f1_score(y_train, y_pred_optimized)\n",
    "optimized_accuracy = accuracy_score(y_train, y_pred_optimized)\n",
    "\n",
    "# 3. Evaluación con el modelo optimizado y el mejor umbral\n",
    "y_pred_best_threshold = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "best_threshold_f1 = f1_score(y_train, y_pred_best_threshold)\n",
    "best_threshold_accuracy = accuracy_score(y_train, y_pred_best_threshold)\n",
    "\n",
    "# Comparación de métricas\n",
    "print(\"Comparación de métricas:\")\n",
    "print(f\"{'Modelo':<30}{'F1-Score':<15}{'Accuracy':<15}\")\n",
    "print(f\"{'Modelo inicial (umbral 0.5)':<30}{initial_f1:<15.4f}{initial_accuracy:<15.4f}\")\n",
    "print(f\"{'Modelo optimizado (umbral 0.5)':<30}{optimized_f1:<15.4f}{optimized_accuracy:<15.4f}\")\n",
    "print(f\"{'Modelo optimizado (mejor umbral)':<30}{best_threshold_f1:<15.4f}{best_threshold_accuracy:<15.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo optimizado con el mejor umbral fue seleccionado como el mejor modelo.\n",
      "Reporte de clasificación en el conjunto de prueba:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.70      0.69       108\n",
      "           1       0.63      0.60      0.61        92\n",
      "\n",
      "    accuracy                           0.66       200\n",
      "   macro avg       0.65      0.65      0.65       200\n",
      "weighted avg       0.65      0.66      0.65       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selección del mejor modelo según F1-score\n",
    "if best_threshold_f1 >= max(initial_f1, optimized_f1):\n",
    "    final_model = optimized_model\n",
    "    final_threshold = optimal_threshold\n",
    "    print(\"El modelo optimizado con el mejor umbral fue seleccionado como el mejor modelo.\")\n",
    "else:\n",
    "    final_model = optimized_model if optimized_f1 > initial_f1 else initial_model\n",
    "    final_threshold = 0.5\n",
    "    print(\"El modelo optimizado o inicial con umbral 0.5 fue seleccionado como el mejor modelo.\")\n",
    "\n",
    "# Entrenar el modelo final con los datos de entrenamiento completos\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo final en el conjunto de prueba\n",
    "y_test_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_proba >= final_threshold).astype(int)\n",
    "\n",
    "# Reporte de clasificación en el conjunto de prueba\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Reporte de clasificación en el conjunto de prueba:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta de models_dir: c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\data\\models\n"
     ]
    }
   ],
   "source": [
    "models_dir = os.path.join(BASE_DIR, 'models')\n",
    "print(f\"Ruta de models_dir: {models_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando la carpeta existente: c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\data\\models\n",
      "Modelo guardado en: c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\data\\models\\naive_bayes_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Ajustar la ruta de models_dir para que apunte fuera de 'data'\n",
    "models_dir = os.path.join(BASE_DIR, 'models')  # Asegúrate de que apunta al directorio correcto\n",
    "\n",
    "# Crear la carpeta 'models' si no existe\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    print(f\"Carpeta 'models' creada en: {models_dir}\")\n",
    "else:\n",
    "    print(f\"Usando la carpeta existente: {models_dir}\")\n",
    "\n",
    "# Ruta para guardar el modelo\n",
    "model_path = os.path.join(models_dir, 'naive_bayes_best_model.pkl')\n",
    "\n",
    "# Guardar el modelo final\n",
    "joblib.dump(final_model, model_path)\n",
    "print(f\"Modelo guardado en: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:03:28 INFO mlflow.tracking.fluent: Autologging successfully enabled for lightgbm.\n",
      "2025/07/08 13:03:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2025/07/08 13:03:29 INFO mlflow.tracking.fluent: Autologging successfully enabled for xgboost.\n",
      "2025/07/08 13:03:32 INFO mlflow.tracking.fluent: Experiment with name 'Toxicity Classification Benchmarking' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base directory: c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\data\n",
      "Data directory: c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\data\\processed\n",
      "Models directory: c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\data\\models\n",
      "\n",
      "Verificando archivos necesarios...\n",
      "✅ X_train_tfidf.pkl\n",
      "✅ X_test_tfidf.pkl\n",
      "✅ y_train.csv\n",
      "✅ y_test.csv\n",
      "\n",
      "Cargando datos...\n",
      "✅ Datos cargados exitosamente\n",
      "X_train shape: (800, 2968)\n",
      "X_test shape: (200, 2968)\n",
      "y_train shape: (800,)\n",
      "y_test shape: (200,)\n",
      "Distribución de clases en train: IsToxic\n",
      "0    430\n",
      "1    370\n",
      "Name: count, dtype: int64\n",
      "Distribución de clases en test: IsToxic\n",
      "0    108\n",
      "1     92\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Aplicando SMOTE...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:03:33 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'a3ceae71a5df4efdacdc14b942a66c56', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2025/07/08 13:03:37 WARNING mlflow.sklearn: Training metrics will not be recorded because training labels were not specified. To automatically record training metrics, provide training labels as inputs to the model training function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run languid-snipe-245 at: http://localhost:5000/#/experiments/968302732310395226/runs/a3ceae71a5df4efdacdc14b942a66c56\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/968302732310395226\n",
      "✅ SMOTE aplicado exitosamente\n",
      "Distribución después de SMOTE: IsToxic\n",
      "1    430\n",
      "0    430\n",
      "Name: count, dtype: int64\n",
      "X_train_res shape: (860, 2968)\n",
      "\n",
      "🚀 Iniciando entrenamiento de modelos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:03:38 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando LogisticRegression con parámetros: {'C': 1.0, 'max_iter': 1000, 'random_state': 42, 'solver': 'liblinear'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:03:54 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/08 13:04:45 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LogisticRegression completado\n",
      "   Accuracy: 0.7350\n",
      "   F1 Score: 0.7330\n",
      "   Recall Toxic: 0.6522\n",
      "   Precision Toxic: 0.7407\n",
      "🏃 View run LogisticRegression_toxicity at: http://localhost:5000/#/experiments/968302732310395226/runs/3f84ad321455463098d7948e3c8f812f\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/968302732310395226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:04:48 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando RandomForestClassifier con parámetros: {'bootstrap': True, 'max_depth': 15, 'max_features': 'sqrt', 'min_samples_leaf': 6, 'min_samples_split': 7, 'n_estimators': 135, 'random_state': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:05:02 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/08 13:05:37 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ RandomForestClassifier completado\n",
      "   Accuracy: 0.7450\n",
      "   F1 Score: 0.7372\n",
      "   Recall Toxic: 0.5761\n",
      "   Precision Toxic: 0.8154\n",
      "🏃 View run RandomForestClassifier_toxicity at: http://localhost:5000/#/experiments/968302732310395226/runs/f95b99cf07d4403c88430eb6ed07f7a7\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/968302732310395226\n",
      "\n",
      "Entrenando XGBClassifier con parámetros: {'colsample_bytree': 0.8, 'eval_metric': 'logloss', 'gamma': 0, 'learning_rate': 0.1, 'max_depth': 6, 'n_estimators': 125, 'random_state': 42, 'reg_alpha': 0.1, 'reg_lambda': 1, 'subsample': 0.8, 'use_label_encoder': False}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [13:05:40] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "2025/07/08 13:06:04 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/08 13:06:36 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ XGBClassifier completado\n",
      "   Accuracy: 0.7300\n",
      "   F1 Score: 0.7233\n",
      "   Recall Toxic: 0.5761\n",
      "   Precision Toxic: 0.7794\n",
      "🏃 View run XGBClassifier_toxicity at: http://localhost:5000/#/experiments/968302732310395226/runs/dbe31fe7a29642f59065e7c9243d0be8\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/968302732310395226\n",
      "\n",
      "Entrenando LGBMClassifier con parámetros: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': -1, 'min_child_samples': 20, 'n_estimators': 125, 'num_leaves': 31, 'random_state': 42, 'subsample': 0.8, 'verbosity': -1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "2025/07/08 13:13:05 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/08 13:13:58 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LGBMClassifier completado\n",
      "   Accuracy: 0.7150\n",
      "   F1 Score: 0.7109\n",
      "   Recall Toxic: 0.5978\n",
      "   Precision Toxic: 0.7333\n",
      "🏃 View run LGBMClassifier_toxicity at: http://localhost:5000/#/experiments/968302732310395226/runs/72530331d049460f9ee821cc0196789f\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/968302732310395226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:14:02 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando KNeighborsClassifier con parámetros: {'metric': 'cosine', 'n_neighbors': 7, 'weights': 'uniform'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:14:14 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/08 13:15:00 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ KNeighborsClassifier completado\n",
      "   Accuracy: 0.6400\n",
      "   F1 Score: 0.6405\n",
      "   Recall Toxic: 0.6630\n",
      "   Precision Toxic: 0.5980\n",
      "🏃 View run KNeighborsClassifier_toxicity at: http://localhost:5000/#/experiments/968302732310395226/runs/5332b58f9a7f4648a10ce230cfb84854\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/968302732310395226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:15:01 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando GradientBoostingClassifier con parámetros: {'learning_rate': 0.1, 'max_depth': 6, 'max_features': 'sqrt', 'min_samples_leaf': 6, 'min_samples_split': 8, 'n_estimators': 110, 'random_state': 42, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:15:17 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/08 13:15:42 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ GradientBoostingClassifier completado\n",
      "   Accuracy: 0.7400\n",
      "   F1 Score: 0.7366\n",
      "   Recall Toxic: 0.6304\n",
      "   Precision Toxic: 0.7632\n",
      "🏃 View run GradientBoostingClassifier_toxicity at: http://localhost:5000/#/experiments/968302732310395226/runs/441460812868432c95ca972f940db9c8\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/968302732310395226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:15:44 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando GaussianNB con parámetros: {}\n",
      "❌ Error entrenando GaussianNB: Sparse data was passed for X, but dense data is required. Use '.toarray()' to convert to a dense numpy array.\n",
      "🏃 View run GaussianNB_toxicity at: http://localhost:5000/#/experiments/968302732310395226/runs/9aa8baceec1b4c29a13fdb2f436d40f3\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/968302732310395226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:15:47 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando SVC con parámetros: {'C': 1.0, 'kernel': 'linear', 'probability': True, 'random_state': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:16:00 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/08 13:17:01 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SVC completado\n",
      "   Accuracy: 0.7250\n",
      "   F1 Score: 0.7234\n",
      "   Recall Toxic: 0.6522\n",
      "   Precision Toxic: 0.7229\n",
      "🏃 View run SVC_toxicity at: http://localhost:5000/#/experiments/968302732310395226/runs/cebccab118fa4afd8e953266968ba534\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/968302732310395226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:17:02 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Entrenando ExtraTreesClassifier con parámetros: {'max_depth': 10, 'n_estimators': 100, 'random_state': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/08 13:17:19 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/07/08 13:18:34 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ ExtraTreesClassifier completado\n",
      "   Accuracy: 0.7000\n",
      "   F1 Score: 0.6878\n",
      "   Recall Toxic: 0.5000\n",
      "   Precision Toxic: 0.7667\n",
      "🏃 View run ExtraTreesClassifier_toxicity at: http://localhost:5000/#/experiments/968302732310395226/runs/61a494a0e8cf49329f67c17da926fc68\n",
      "🧪 View experiment at: http://localhost:5000/#/experiments/968302732310395226\n",
      "\n",
      "============================================================\n",
      "🎉 ENTRENAMIENTO COMPLETADO!\n",
      "============================================================\n",
      "\n",
      "📊 RANKING DE MODELOS (por F1 Score):\n",
      "------------------------------------------------------------\n",
      "RandomForestClassifier    | F1: 0.7372 | Acc: 0.7450 | Recall Toxic: 0.5761\n",
      "GradientBoostingClassifier | F1: 0.7366 | Acc: 0.7400 | Recall Toxic: 0.6304\n",
      "LogisticRegression        | F1: 0.7330 | Acc: 0.7350 | Recall Toxic: 0.6522\n",
      "SVC                       | F1: 0.7234 | Acc: 0.7250 | Recall Toxic: 0.6522\n",
      "XGBClassifier             | F1: 0.7233 | Acc: 0.7300 | Recall Toxic: 0.5761\n",
      "LGBMClassifier            | F1: 0.7109 | Acc: 0.7150 | Recall Toxic: 0.5978\n",
      "ExtraTreesClassifier      | F1: 0.6878 | Acc: 0.7000 | Recall Toxic: 0.5000\n",
      "KNeighborsClassifier      | F1: 0.6405 | Acc: 0.6400 | Recall Toxic: 0.6630\n",
      "\n",
      "💾 Resultados guardados en: c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\data\\models\\model_comparison.csv\n",
      "\n",
      "🏆 MEJOR MODELO: RandomForestClassifier\n",
      "   F1 Score: 0.7372\n",
      "   Accuracy: 0.7450\n",
      "   Recall Toxic: 0.5761\n",
      "\n",
      "🔍 Revisa los experimentos en MLflow: http://localhost:5000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, f1_score, recall_score\n",
    ")\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import clone\n",
    "\n",
    "# ✅ Llamada correcta a autolog\n",
    "mlflow.autolog(log_models=False)\n",
    "\n",
    "# MLflow config\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Toxicity Classification Benchmarking\")\n",
    "\n",
    "# Definir directorios\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "data_dir = os.path.join(BASE_DIR, 'processed')\n",
    "models_dir = os.path.join(BASE_DIR, 'models')\n",
    "\n",
    "print(f\"Base directory: {BASE_DIR}\")\n",
    "print(f\"Data directory: {data_dir}\")\n",
    "print(f\"Models directory: {models_dir}\")\n",
    "\n",
    "# Verificar que los directorios existen\n",
    "if not os.path.exists(data_dir):\n",
    "    raise FileNotFoundError(f\"Directory not found: {data_dir}\")\n",
    "\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    print(f\"Created models directory: {models_dir}\")\n",
    "\n",
    "# Verificar archivos necesarios\n",
    "required_files = [\n",
    "    'X_train_tfidf.pkl',\n",
    "    'X_test_tfidf.pkl',\n",
    "    'y_train.csv',\n",
    "    'y_test.csv'\n",
    "]\n",
    "\n",
    "print(\"\\nVerificando archivos necesarios...\")\n",
    "for file in required_files:\n",
    "    file_path = os.path.join(data_dir, file)\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"✅ {file}\")\n",
    "    else:\n",
    "        print(f\"❌ {file} - NOT FOUND\")\n",
    "        raise FileNotFoundError(f\"Required file not found: {file_path}\")\n",
    "\n",
    "# Cargar datos vectorizados\n",
    "print(\"\\nCargando datos...\")\n",
    "try:\n",
    "    X_train = joblib.load(os.path.join(data_dir, 'X_train_tfidf.pkl'))\n",
    "    X_test = joblib.load(os.path.join(data_dir, 'X_test_tfidf.pkl'))\n",
    "    \n",
    "    # Cargar etiquetas\n",
    "    y_train = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))['IsToxic']\n",
    "    y_test = pd.read_csv(os.path.join(data_dir, 'y_test.csv'))['IsToxic']\n",
    "    \n",
    "    print(f\"✅ Datos cargados exitosamente\")\n",
    "    print(f\"X_train shape: {X_train.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}\")\n",
    "    print(f\"y_train shape: {y_train.shape}\")\n",
    "    print(f\"y_test shape: {y_test.shape}\")\n",
    "    print(f\"Distribución de clases en train: {y_train.value_counts()}\")\n",
    "    print(f\"Distribución de clases en test: {y_test.value_counts()}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error cargando datos: {str(e)}\")\n",
    "    raise\n",
    "\n",
    "# Aplicar SMOTE para balancear las clases\n",
    "print(\"\\nAplicando SMOTE...\")\n",
    "try:\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "    print(f\"✅ SMOTE aplicado exitosamente\")\n",
    "    print(f\"Distribución después de SMOTE: {pd.Series(y_train_res).value_counts()}\")\n",
    "    print(f\"X_train_res shape: {X_train_res.shape}\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error aplicando SMOTE: {str(e)}\")\n",
    "    print(\"Continuando sin SMOTE...\")\n",
    "    X_train_res, y_train_res = X_train, y_train\n",
    "\n",
    "# Hiperparámetros adaptados para clasificación de texto\n",
    "params = {\n",
    "    \"RandomForestClassifier\": {\n",
    "        'n_estimators': [135], \n",
    "        'max_depth': [15], \n",
    "        'min_samples_split': [7],\n",
    "        'min_samples_leaf': [6], \n",
    "        'max_features': ['sqrt'], \n",
    "        'bootstrap': [True], \n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \"KNeighborsClassifier\": {\n",
    "        'n_neighbors': [7], \n",
    "        'weights': ['uniform'], \n",
    "        'metric': ['cosine']  # Mejor para datos de texto\n",
    "    },\n",
    "    \"GradientBoostingClassifier\": {\n",
    "        'n_estimators': [110], \n",
    "        'learning_rate': [0.1],  # Reducido para estabilidad\n",
    "        'max_depth': [6],  # Reducido para datos de texto\n",
    "        'min_samples_split': [8], \n",
    "        'min_samples_leaf': [6], \n",
    "        'subsample': [0.8],\n",
    "        'max_features': ['sqrt'], \n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \"LGBMClassifier\": {\n",
    "        'n_estimators': [125], \n",
    "        'learning_rate': [0.1], \n",
    "        'num_leaves': [31], \n",
    "        'max_depth': [-1],\n",
    "        'min_child_samples': [20], \n",
    "        'subsample': [0.8], \n",
    "        'colsample_bytree': [0.8], \n",
    "        'random_state': [42],\n",
    "        'verbosity': [-1]\n",
    "    },\n",
    "    \"XGBClassifier\": {\n",
    "        'n_estimators': [125], \n",
    "        'learning_rate': [0.1], \n",
    "        'max_depth': [6], \n",
    "        'subsample': [0.8],\n",
    "        'colsample_bytree': [0.8], \n",
    "        'gamma': [0], \n",
    "        'reg_alpha': [0.1], \n",
    "        'reg_lambda': [1],\n",
    "        'use_label_encoder': [False], \n",
    "        'eval_metric': ['logloss'], \n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \"LogisticRegression\": {\n",
    "        'C': [1.0], \n",
    "        'max_iter': [1000],  # Aumentado para convergencia\n",
    "        'solver': ['liblinear'],  # Mejor para datos sparse\n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \"GaussianNB\": [{}],\n",
    "    \"SVC\": {\n",
    "        'C': [1.0], \n",
    "        'kernel': ['linear'],  # Linear mejor para texto\n",
    "        'probability': [True], \n",
    "        'random_state': [42]\n",
    "    },\n",
    "    \"ExtraTreesClassifier\": {\n",
    "        'n_estimators': [100], \n",
    "        'max_depth': [10], \n",
    "        'random_state': [42]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Modelos\n",
    "modelos = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(),\n",
    "    \"LGBMClassifier\": LGBMClassifier(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(),\n",
    "}\n",
    "\n",
    "# Entrenamiento y tracking\n",
    "print(\"\\n🚀 Iniciando entrenamiento de modelos...\")\n",
    "\n",
    "results = []\n",
    "\n",
    "for nombre, modelo in modelos.items():\n",
    "    grid = params.get(nombre, [{}])\n",
    "    for param_set in ParameterGrid(grid):\n",
    "        m = clone(modelo)\n",
    "        m.set_params(**param_set)\n",
    "\n",
    "        with mlflow.start_run(run_name=f\"{nombre}_toxicity\"):\n",
    "            print(f\"\\nEntrenando {nombre} con parámetros: {param_set}\")\n",
    "            \n",
    "            try:\n",
    "                # Entrenar modelo\n",
    "                m.fit(X_train_res, y_train_res)\n",
    "\n",
    "                # Predicciones\n",
    "                y_train_pred = m.predict(X_train_res)\n",
    "                y_test_pred = m.predict(X_test)\n",
    "\n",
    "                # Métricas\n",
    "                acc_train = accuracy_score(y_train_res, y_train_pred)\n",
    "                acc_test = accuracy_score(y_test, y_test_pred)\n",
    "                f1_train = f1_score(y_train_res, y_train_pred, average='weighted')\n",
    "                f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "                acc_gap = acc_train - acc_test\n",
    "                f1_gap = f1_train - f1_test\n",
    "\n",
    "                # Reporte de clasificación\n",
    "                report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "                \n",
    "                # Recall por clase (0: no tóxico, 1: tóxico)\n",
    "                recall_0 = report.get('0', {}).get('recall', 0)\n",
    "                recall_1 = report.get('1', {}).get('recall', 0)\n",
    "                \n",
    "                # Precisión por clase\n",
    "                precision_0 = report.get('0', {}).get('precision', 0)\n",
    "                precision_1 = report.get('1', {}).get('precision', 0)\n",
    "                \n",
    "                # F1 por clase\n",
    "                f1_0 = report.get('0', {}).get('f1-score', 0)\n",
    "                f1_1 = report.get('1', {}).get('f1-score', 0)\n",
    "\n",
    "                # MLflow logs\n",
    "                mlflow.log_param(\"modelo\", nombre)\n",
    "                mlflow.log_params(param_set)\n",
    "                mlflow.log_metric(\"accuracy_train\", acc_train)\n",
    "                mlflow.log_metric(\"accuracy_test\", acc_test)\n",
    "                mlflow.log_metric(\"f1_train\", f1_train)\n",
    "                mlflow.log_metric(\"f1_test\", f1_test)\n",
    "                mlflow.log_metric(\"acc_gap\", acc_gap)\n",
    "                mlflow.log_metric(\"f1_gap\", f1_gap)\n",
    "                mlflow.log_metric(\"recall_non_toxic\", recall_0)\n",
    "                mlflow.log_metric(\"recall_toxic\", recall_1)\n",
    "                mlflow.log_metric(\"precision_non_toxic\", precision_0)\n",
    "                mlflow.log_metric(\"precision_toxic\", precision_1)\n",
    "                mlflow.log_metric(\"f1_non_toxic\", f1_0)\n",
    "                mlflow.log_metric(\"f1_toxic\", f1_1)\n",
    "\n",
    "                # Guardar el modelo\n",
    "                mlflow.sklearn.log_model(m, artifact_path=\"modelo\")\n",
    "                \n",
    "                # Guardar también en el directorio de modelos\n",
    "                model_path = os.path.join(models_dir, f\"{nombre}_toxicity.pkl\")\n",
    "                joblib.dump(m, model_path)\n",
    "                \n",
    "                print(f\"✅ {nombre} completado\")\n",
    "                print(f\"   Accuracy: {acc_test:.4f}\")\n",
    "                print(f\"   F1 Score: {f1_test:.4f}\")\n",
    "                print(f\"   Recall Toxic: {recall_1:.4f}\")\n",
    "                print(f\"   Precision Toxic: {precision_1:.4f}\")\n",
    "                \n",
    "                # Guardar resultados para comparación\n",
    "                results.append({\n",
    "                    'modelo': nombre,\n",
    "                    'accuracy_test': acc_test,\n",
    "                    'f1_test': f1_test,\n",
    "                    'recall_toxic': recall_1,\n",
    "                    'precision_toxic': precision_1,\n",
    "                    'acc_gap': acc_gap,\n",
    "                    'f1_gap': f1_gap\n",
    "                })\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"❌ Error entrenando {nombre}: {str(e)}\")\n",
    "                mlflow.log_param(\"error\", str(e))\n",
    "                continue\n",
    "\n",
    "# Resumen de resultados\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎉 ENTRENAMIENTO COMPLETADO!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if results:\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values('f1_test', ascending=False)\n",
    "    \n",
    "    print(\"\\n📊 RANKING DE MODELOS (por F1 Score):\")\n",
    "    print(\"-\" * 60)\n",
    "    for idx, row in results_df.iterrows():\n",
    "        print(f\"{row['modelo']:<25} | F1: {row['f1_test']:.4f} | Acc: {row['accuracy_test']:.4f} | Recall Toxic: {row['recall_toxic']:.4f}\")\n",
    "    \n",
    "    # Guardar resultados\n",
    "    results_path = os.path.join(models_dir, 'model_comparison.csv')\n",
    "    results_df.to_csv(results_path, index=False)\n",
    "    print(f\"\\n💾 Resultados guardados en: {results_path}\")\n",
    "    \n",
    "    best_model = results_df.iloc[0]['modelo']\n",
    "    print(f\"\\n🏆 MEJOR MODELO: {best_model}\")\n",
    "    print(f\"   F1 Score: {results_df.iloc[0]['f1_test']:.4f}\")\n",
    "    print(f\"   Accuracy: {results_df.iloc[0]['accuracy_test']:.4f}\")\n",
    "    print(f\"   Recall Toxic: {results_df.iloc[0]['recall_toxic']:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(\"❌ No se completó el entrenamiento de ningún modelo\")\n",
    "\n",
    "print(f\"\\n🔍 Revisa los experimentos en MLflow: http://localhost:5000\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "import mlflow\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # ... tu código del modelo ...\n",
    "\n",
    "    ram_usage = psutil.virtual_memory().used / (1024 ** 3)  # en GB\n",
    "    cpu_usage = psutil.cpu_percent()\n",
    "\n",
    "    mlflow.log_metric(\"ram_used_gb\", ram_usage)\n",
    "    mlflow.log_metric(\"cpu_percent\", cpu_usage)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
