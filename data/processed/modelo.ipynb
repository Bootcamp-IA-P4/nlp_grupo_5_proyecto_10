{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librer√≠as m√°gicas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, classification_report\n",
    "import optuna\n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/fintihlupik/NLP-sentimental/refs/heads/master/data/youtoxic_english_1000%20-%20youtoxic_english_1000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir directorios\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "data_dir = os.path.join(BASE_DIR, 'processed')  # Corregido\n",
    "models_dir = os.path.join(BASE_DIR, 'models')\n",
    "\n",
    "# Cargar datos vectorizados\n",
    "X_train = joblib.load(os.path.join(data_dir, 'X_train_tfidf.pkl'))\n",
    "X_test = joblib.load(os.path.join(data_dir, 'X_test_tfidf.pkl'))\n",
    "\n",
    "# Cargar etiquetas\n",
    "y_train = pd.read_csv(os.path.join(data_dir, 'y_train.csv'))['IsToxic']\n",
    "y_test = pd.read_csv(os.path.join(data_dir, 'y_test.csv'))['IsToxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-Score inicial: 0.7077\n",
      "Reporte de clasificaci√≥n inicial:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.42      0.56       430\n",
      "           1       0.58      0.92      0.71       370\n",
      "\n",
      "    accuracy                           0.65       800\n",
      "   macro avg       0.72      0.67      0.64       800\n",
      "weighted avg       0.73      0.65      0.63       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_curve, f1_score, classification_report\n",
    "\n",
    "# Configuraci√≥n de validaci√≥n cruzada estratificada\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Modelo inicial con Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# Evaluaci√≥n inicial con validaci√≥n cruzada\n",
    "y_pred_proba = cross_val_predict(nb_model, X_train, y_train, cv=skf, method='predict_proba')[:, 1]\n",
    "\n",
    "# Calcular m√©tricas de evaluaci√≥n\n",
    "precision, recall, thresholds = precision_recall_curve(y_train, y_pred_proba)\n",
    "f1_scores = 2 * recall * precision / (recall + precision + 1e-6)\n",
    "\n",
    "# Imprimir resultados iniciales\n",
    "print(f\"F1-Score inicial: {max(f1_scores):.4f}\")\n",
    "\n",
    "# Reporte de clasificaci√≥n inicial\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "y_pred = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "print(\"Reporte de clasificaci√≥n inicial:\")\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-07-07 14:10:29,516] A new study created in memory with name: no-name-b9de55ed-df98-471d-bf23-2d9bb59aa9e9\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:29,747] Trial 0 finished with value: 0.6951359250209992 and parameters: {'alpha': 0.0049281114939941926}. Best is trial 0 with value: 0.6951359250209992.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:29,989] Trial 1 finished with value: 0.7073469501514792 and parameters: {'alpha': 7.600564748763602}. Best is trial 1 with value: 0.7073469501514792.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:30,156] Trial 2 finished with value: 0.7113767519814103 and parameters: {'alpha': 0.11678677562935426}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:30,360] Trial 3 finished with value: 0.7061606450330247 and parameters: {'alpha': 0.011845194122068805}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:30,751] Trial 4 finished with value: 0.7041279518246802 and parameters: {'alpha': 2.3137092336294574}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:31,124] Trial 5 finished with value: 0.7107838180631101 and parameters: {'alpha': 0.14430806975180055}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:31,236] Trial 6 finished with value: 0.6843925740255431 and parameters: {'alpha': 0.002139838747214192}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:31,365] Trial 7 finished with value: 0.7108690843576033 and parameters: {'alpha': 0.16887742952481477}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:31,518] Trial 8 finished with value: 0.7055895653720562 and parameters: {'alpha': 2.0591832426692815}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:31,630] Trial 9 finished with value: 0.7039995119023793 and parameters: {'alpha': 2.6471360319086403}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:32,123] Trial 10 finished with value: 0.7076218105695394 and parameters: {'alpha': 0.03208340696350913}. Best is trial 2 with value: 0.7113767519814103.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:32,268] Trial 11 finished with value: 0.711642609284912 and parameters: {'alpha': 0.19479802013381706}. Best is trial 11 with value: 0.711642609284912.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:32,567] Trial 12 finished with value: 0.7103372981023076 and parameters: {'alpha': 0.3729452282296344}. Best is trial 11 with value: 0.711642609284912.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:32,775] Trial 13 finished with value: 0.7075466779217552 and parameters: {'alpha': 0.027715837617233778}. Best is trial 11 with value: 0.711642609284912.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:32,922] Trial 14 finished with value: 0.7121029162625372 and parameters: {'alpha': 0.4259400922426271}. Best is trial 14 with value: 0.7121029162625372.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:33,024] Trial 15 finished with value: 0.7165254406245181 and parameters: {'alpha': 0.5191084056268539}. Best is trial 15 with value: 0.7165254406245181.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:33,184] Trial 16 finished with value: 0.7177028558758916 and parameters: {'alpha': 0.48942713832142165}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:33,304] Trial 17 finished with value: 0.7098316406446624 and parameters: {'alpha': 0.7482980184518642}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:33,577] Trial 18 finished with value: 0.70804548817579 and parameters: {'alpha': 0.04087135772845346}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:33,777] Trial 19 finished with value: 0.711216690609304 and parameters: {'alpha': 0.682797792740209}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:33,960] Trial 20 finished with value: 0.7082289294224295 and parameters: {'alpha': 1.216690170309972}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:34,075] Trial 21 finished with value: 0.7104332719637154 and parameters: {'alpha': 0.391896224073452}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:34,262] Trial 22 finished with value: 0.7055895653720562 and parameters: {'alpha': 7.01916934394026}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:34,423] Trial 23 finished with value: 0.711216690609304 and parameters: {'alpha': 0.6959917484154714}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:34,670] Trial 24 finished with value: 0.7100451741522505 and parameters: {'alpha': 0.05996868293382539}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:34,835] Trial 25 finished with value: 0.7106705843898999 and parameters: {'alpha': 0.29455308909418565}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:34,953] Trial 26 finished with value: 0.710525822383072 and parameters: {'alpha': 0.08196182696485815}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,062] Trial 27 finished with value: 0.7036565009727636 and parameters: {'alpha': 3.7383007122965917}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,122] Trial 28 finished with value: 0.7073469501514792 and parameters: {'alpha': 1.1777397743126068}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,191] Trial 29 finished with value: 0.7028296967896822 and parameters: {'alpha': 0.01017675224489041}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,257] Trial 30 finished with value: 0.7106705843898999 and parameters: {'alpha': 0.2929195960163209}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,359] Trial 31 finished with value: 0.7135011641593245 and parameters: {'alpha': 0.2146696555777529}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,423] Trial 32 finished with value: 0.7163456599601223 and parameters: {'alpha': 0.5632822760786169}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,485] Trial 33 finished with value: 0.7091131108901383 and parameters: {'alpha': 1.057028686577727}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,549] Trial 34 finished with value: 0.7113767519814103 and parameters: {'alpha': 0.09013008664817482}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,621] Trial 35 finished with value: 0.711642609284912 and parameters: {'alpha': 0.19420573425656834}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,700] Trial 36 finished with value: 0.7161671711430846 and parameters: {'alpha': 0.47069193123792175}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,767] Trial 37 finished with value: 0.7058818556678697 and parameters: {'alpha': 1.5869591305568547}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,834] Trial 38 finished with value: 0.7078080665447732 and parameters: {'alpha': 4.524593323027234}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,921] Trial 39 finished with value: 0.7144588003469985 and parameters: {'alpha': 0.6118536941652083}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:35,993] Trial 40 finished with value: 0.6827028334839198 and parameters: {'alpha': 0.0016760863371067102}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:36,073] Trial 41 finished with value: 0.7151510204594791 and parameters: {'alpha': 0.5956571925782038}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:36,152] Trial 42 finished with value: 0.7165254406245181 and parameters: {'alpha': 0.5186235065681171}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:36,217] Trial 43 finished with value: 0.7106705843898999 and parameters: {'alpha': 0.1304627855952903}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:36,304] Trial 44 finished with value: 0.7055895653720562 and parameters: {'alpha': 2.040372967252789}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:36,386] Trial 45 finished with value: 0.7077239517787705 and parameters: {'alpha': 0.9708154143532864}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:36,446] Trial 46 finished with value: 0.7144558985913431 and parameters: {'alpha': 0.4461552076433735}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:36,527] Trial 47 finished with value: 0.7130237993463601 and parameters: {'alpha': 0.2539167787837999}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:36,590] Trial 48 finished with value: 0.703378726756732 and parameters: {'alpha': 3.1783844693357386}. Best is trial 16 with value: 0.7177028558758916.\n",
      "C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_16688\\3703045900.py:6: FutureWarning: suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "  alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
      "[I 2025-07-07 14:10:36,654] Trial 49 finished with value: 0.7064798067391452 and parameters: {'alpha': 1.8091335234939843}. Best is trial 16 with value: 0.7177028558758916.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejor valor de alpha: 0.48942713832142165\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "# Definir funci√≥n objetivo para Optuna\n",
    "def objective(trial):\n",
    "    # Sugerir un valor para el hiperpar√°metro alpha\n",
    "    alpha = trial.suggest_loguniform('alpha', 1e-3, 10.0)\n",
    "    \n",
    "    # Crear el modelo con el valor de alpha sugerido\n",
    "    model = MultinomialNB(alpha=alpha)\n",
    "    \n",
    "    # Validaci√≥n cruzada estratificada\n",
    "    y_pred_proba = cross_val_predict(model, X_train, y_train, cv=skf, method='predict_proba')[:, 1]\n",
    "    \n",
    "    # Calcular F1-score\n",
    "    precision, recall, thresholds = precision_recall_curve(y_train, y_pred_proba)\n",
    "    f1_scores = 2 * recall * precision / (recall + precision + 1e-6)\n",
    "    \n",
    "    # Retornar el mejor F1-score\n",
    "    return max(f1_scores)\n",
    "\n",
    "# Crear un estudio de Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=50)  # Ejecutar 50 pruebas\n",
    "\n",
    "# Obtener el mejor hiperpar√°metro\n",
    "best_alpha = study.best_params['alpha']\n",
    "print(f\"Mejor valor de alpha: {best_alpha}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/07 14:10:39 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'db5ec86d8c1b471489e2b42f7b65179a', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2025/07/07 14:10:39 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run silent-pig-636 at: http://localhost:5000/#/experiments/168441151506597017/runs/db5ec86d8c1b471489e2b42f7b65179a\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/168441151506597017\n",
      "Mejor umbral para F1-score: 0.4902\n",
      "Reporte de clasificaci√≥n con umbral optimizado:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       430\n",
      "           1       0.96      0.98      0.97       370\n",
      "\n",
      "    accuracy                           0.97       800\n",
      "   macro avg       0.97      0.97      0.97       800\n",
      "weighted avg       0.97      0.97      0.97       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo con el mejor valor de alpha encontrado por Optuna\n",
    "best_model = MultinomialNB(alpha=best_alpha)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Obtener las probabilidades predichas en el conjunto de entrenamiento\n",
    "y_pred_proba = best_model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# Calcular precisi√≥n, recall y F1-score para diferentes umbrales\n",
    "precision, recall, thresholds = precision_recall_curve(y_train, y_pred_proba)\n",
    "f1_scores = 2 * recall * precision / (recall + precision + 1e-6)\n",
    "\n",
    "# Encontrar el umbral que maximiza el F1-score\n",
    "optimal_threshold = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Mejor umbral para F1-score: {optimal_threshold:.4f}\")\n",
    "\n",
    "# Evaluar el modelo con el umbral √≥ptimo\n",
    "y_pred_optimal = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "print(\"Reporte de clasificaci√≥n con umbral optimizado:\")\n",
    "print(classification_report(y_train, y_pred_optimal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/07 14:11:14 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '42fce0316cf645b1ba71843bb94394c5', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2025/07/07 14:11:15 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run amusing-grouse-227 at: http://localhost:5000/#/experiments/168441151506597017/runs/42fce0316cf645b1ba71843bb94394c5\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/168441151506597017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/07 14:11:26 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '228f46f7150e4eaba316183c90b65cac', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2025/07/07 14:11:27 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run sincere-sow-120 at: http://localhost:5000/#/experiments/168441151506597017/runs/228f46f7150e4eaba316183c90b65cac\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/168441151506597017\n",
      "Comparaci√≥n de m√©tricas:\n",
      "Modelo                        F1-Score       Accuracy       \n",
      "Modelo inicial (umbral 0.5)   0.9392         0.9450         \n",
      "Modelo optimizado (umbral 0.5)0.9636         0.9663         \n",
      "Modelo optimizado (mejor umbral)0.9665         0.9688         \n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 1. Evaluaci√≥n con el modelo inicial (umbral predeterminado de 0.5)\n",
    "initial_model = MultinomialNB()\n",
    "initial_model.fit(X_train, y_train)\n",
    "y_pred_initial = initial_model.predict(X_train)\n",
    "initial_f1 = f1_score(y_train, y_pred_initial)\n",
    "initial_accuracy = accuracy_score(y_train, y_pred_initial)\n",
    "\n",
    "# 2. Evaluaci√≥n con el modelo optimizado (mejor alpha, umbral predeterminado de 0.5)\n",
    "optimized_model = MultinomialNB(alpha=best_alpha)\n",
    "optimized_model.fit(X_train, y_train)\n",
    "y_pred_optimized = optimized_model.predict(X_train)\n",
    "optimized_f1 = f1_score(y_train, y_pred_optimized)\n",
    "optimized_accuracy = accuracy_score(y_train, y_pred_optimized)\n",
    "\n",
    "# 3. Evaluaci√≥n con el modelo optimizado y el mejor umbral\n",
    "y_pred_best_threshold = (y_pred_proba >= optimal_threshold).astype(int)\n",
    "best_threshold_f1 = f1_score(y_train, y_pred_best_threshold)\n",
    "best_threshold_accuracy = accuracy_score(y_train, y_pred_best_threshold)\n",
    "\n",
    "# Comparaci√≥n de m√©tricas\n",
    "print(\"Comparaci√≥n de m√©tricas:\")\n",
    "print(f\"{'Modelo':<30}{'F1-Score':<15}{'Accuracy':<15}\")\n",
    "print(f\"{'Modelo inicial (umbral 0.5)':<30}{initial_f1:<15.4f}{initial_accuracy:<15.4f}\")\n",
    "print(f\"{'Modelo optimizado (umbral 0.5)':<30}{optimized_f1:<15.4f}{optimized_accuracy:<15.4f}\")\n",
    "print(f\"{'Modelo optimizado (mejor umbral)':<30}{best_threshold_f1:<15.4f}{best_threshold_accuracy:<15.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El modelo optimizado con el mejor umbral fue seleccionado como el mejor modelo.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/07/07 14:11:36 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '69c593107026418e8b8eca2e3b1d5b08', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n",
      "2025/07/07 14:11:36 WARNING mlflow.sklearn: Failed to log training dataset information to MLflow Tracking. Reason: 'Series' object has no attribute 'flatten'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run smiling-gnu-408 at: http://localhost:5000/#/experiments/168441151506597017/runs/69c593107026418e8b8eca2e3b1d5b08\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/168441151506597017\n",
      "Reporte de clasificaci√≥n en el conjunto de prueba:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.73      0.70       108\n",
      "           1       0.65      0.59      0.62        92\n",
      "\n",
      "    accuracy                           0.67       200\n",
      "   macro avg       0.66      0.66      0.66       200\n",
      "weighted avg       0.66      0.67      0.66       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Selecci√≥n del mejor modelo seg√∫n F1-score\n",
    "if best_threshold_f1 >= max(initial_f1, optimized_f1):\n",
    "    final_model = optimized_model\n",
    "    final_threshold = optimal_threshold\n",
    "    print(\"El modelo optimizado con el mejor umbral fue seleccionado como el mejor modelo.\")\n",
    "else:\n",
    "    final_model = optimized_model if optimized_f1 > initial_f1 else initial_model\n",
    "    final_threshold = 0.5\n",
    "    print(\"El modelo optimizado o inicial con umbral 0.5 fue seleccionado como el mejor modelo.\")\n",
    "\n",
    "# Entrenar el modelo final con los datos de entrenamiento completos\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo final en el conjunto de prueba\n",
    "y_test_proba = final_model.predict_proba(X_test)[:, 1]\n",
    "y_test_pred = (y_test_proba >= final_threshold).astype(int)\n",
    "\n",
    "# Reporte de clasificaci√≥n en el conjunto de prueba\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Reporte de clasificaci√≥n en el conjunto de prueba:\")\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta de models_dir: c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\data\\models\n"
     ]
    }
   ],
   "source": [
    "models_dir = os.path.join(BASE_DIR, 'models')\n",
    "print(f\"Ruta de models_dir: {models_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando la carpeta existente: c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\data\\models\n",
      "Modelo guardado en: c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\data\\models\\naive_bayes_best_model.pkl\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "# Ajustar la ruta de models_dir para que apunte fuera de 'data'\n",
    "models_dir = os.path.join(BASE_DIR, 'models')  # Aseg√∫rate de que apunta al directorio correcto\n",
    "\n",
    "# Crear la carpeta 'models' si no existe\n",
    "if not os.path.exists(models_dir):\n",
    "    os.makedirs(models_dir)\n",
    "    print(f\"Carpeta 'models' creada en: {models_dir}\")\n",
    "else:\n",
    "    print(f\"Usando la carpeta existente: {models_dir}\")\n",
    "\n",
    "# Ruta para guardar el modelo\n",
    "model_path = os.path.join(models_dir, 'naive_bayes_best_model.pkl')\n",
    "\n",
    "# Guardar el modelo final\n",
    "joblib.dump(final_model, model_path)\n",
    "print(f\"Modelo guardado en: {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SPARSE_ARRAY_PRESENT' from 'sklearn.utils.fixes' (c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\sklearn\\utils\\fixes.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     16\u001b[39m     accuracy_score, classification_report, f1_score, recall_score\n\u001b[32m     17\u001b[39m )\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParameterGrid\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mimblearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# ‚úÖ Llamada correcta a autolog\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\imblearn\\__init__.py:52\u001b[39m\n\u001b[32m     48\u001b[39m     sys.stderr.write(\u001b[33m\"\u001b[39m\u001b[33mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     49\u001b[39m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[32m     50\u001b[39m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     53\u001b[39m         combine,\n\u001b[32m     54\u001b[39m         ensemble,\n\u001b[32m     55\u001b[39m         exceptions,\n\u001b[32m     56\u001b[39m         metrics,\n\u001b[32m     57\u001b[39m         over_sampling,\n\u001b[32m     58\u001b[39m         pipeline,\n\u001b[32m     59\u001b[39m         tensorflow,\n\u001b[32m     60\u001b[39m         under_sampling,\n\u001b[32m     61\u001b[39m         utils,\n\u001b[32m     62\u001b[39m     )\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_version\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\imblearn\\combine\\__init__.py:5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smote_enn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_smote_tomek\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[32m      8\u001b[39m __all__ = [\u001b[33m\"\u001b[39m\u001b[33mSMOTEENN\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mSMOTETomek\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\imblearn\\combine\\_smote_enn.py:12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mover_sampling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\imblearn\\base.py:15\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_metadata_requests\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m METHODS\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_classification_targets\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_sampling_strategy, check_target_type\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _fit_context, get_tags, validate_data\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ArraysTransformer\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\imblearn\\utils\\__init__.py:6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mThe :mod:`imblearn.utils` module includes various utilities.\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_docstring\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Substitution\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_validation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      7\u001b[39m     check_neighbors_object,\n\u001b[32m      8\u001b[39m     check_sampling_strategy,\n\u001b[32m      9\u001b[39m     check_target_type,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m __all__ = [\n\u001b[32m     13\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_neighbors_object\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_sampling_strategy\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcheck_target_type\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     16\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mSubstitution\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     17\u001b[39m ]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\imblearn\\utils\\_validation.py:20\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _num_samples\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_sklearn_compat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _is_pandas_df, check_array\n\u001b[32m     22\u001b[39m SAMPLING_KIND = (\n\u001b[32m     23\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mover-sampling\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     24\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33munder-sampling\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mbypass\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m )\n\u001b[32m     29\u001b[39m TARGET_KIND = (\u001b[33m\"\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmultilabel-indicator\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\imblearn\\utils\\_sklearn_compat.py:818\u001b[39m\n\u001b[32m    813\u001b[39m     sampler_tags: SamplerTags | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    815\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_test_common\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minstance_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    816\u001b[39m     _construct_instances,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    817\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m818\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mestimator_checks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    819\u001b[39m     check_estimator,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    820\u001b[39m     parametrize_with_checks,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    821\u001b[39m )\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmulticlass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m type_of_target  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[38;5;66;03m# validation\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\sklearn\\utils\\estimator_checks.py:108\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_test_common\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minstance_generator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     90\u001b[39m     CROSS_DECOMPOSITION,\n\u001b[32m     91\u001b[39m     _get_check_estimator_ids,\n\u001b[32m     92\u001b[39m     _yield_instances_for_check,\n\u001b[32m     93\u001b[39m )\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_testing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     95\u001b[39m     SkipTest,\n\u001b[32m     96\u001b[39m     _array_api_for_tests,\n\u001b[32m   (...)\u001b[39m\u001b[32m    106\u001b[39m     set_random_state,\n\u001b[32m    107\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfixes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SPARSE_ARRAY_PRESENT\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mvalidation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m _num_samples, check_is_fitted, has_fit_parameter\n\u001b[32m    111\u001b[39m REGRESSION_DATASET = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'SPARSE_ARRAY_PRESENT' from 'sklearn.utils.fixes' (c:\\Users\\Administrator\\Desktop\\proyecto10\\nlp_grupo_5_proyecto_10\\.venv\\Lib\\site-packages\\sklearn\\utils\\fixes.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestClassifier, GradientBoostingClassifier,\n",
    "    ExtraTreesClassifier\n",
    ")\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, f1_score, recall_score\n",
    ")\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.base import clone\n",
    "\n",
    "# ‚úÖ Llamada correcta a autolog\n",
    "mlflow.autolog(log_models=False)\n",
    "\n",
    "# Resto del c√≥digo...\n",
    " # Logueamos modelos manualmente\n",
    "\n",
    "# MLflow config\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"Full Model Benchmarking\")\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv(\"data/dataset.csv\")\n",
    "X = df.drop(\"stroke\", axis=1)\n",
    "y = df[\"stroke\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Hiperpar√°metros\n",
    "params = {\n",
    "    \"RandomForestClassifier\": {'n_estimators': [135], 'max_depth': [15], 'min_samples_split': [7],\n",
    "                               'min_samples_leaf': [6], 'max_features': ['sqrt'], 'bootstrap': [True], 'random_state': [42]},\n",
    "    \"KNeighborsClassifier\": {'n_neighbors': [7], 'weights': ['uniform'], 'metric': ['minkowski']},\n",
    "    \"GradientBoostingClassifier\": {'n_estimators': [110], 'learning_rate': [0.5], 'max_depth': [15],\n",
    "                                   'min_samples_split': [8], 'min_samples_leaf': [6], 'subsample': [1],\n",
    "                                   'max_features': ['sqrt'], 'random_state': [42]},\n",
    "    \"LGBMClassifier\": {'n_estimators': [125], 'learning_rate': [0.1], 'num_leaves': [31], 'max_depth': [-1],\n",
    "                       'min_child_samples': [20], 'subsample': [1], 'colsample_bytree': [1], 'random_state': [42]},\n",
    "    \"XGBClassifier\": {'n_estimators': [125], 'learning_rate': [1], 'max_depth': [16], 'subsample': [1],\n",
    "                      'colsample_bytree': [1], 'gamma': [0], 'reg_alpha': [0.1], 'reg_lambda': [1],\n",
    "                      'use_label_encoder': [False], 'eval_metric': ['logloss'], 'random_state': [42]},\n",
    "    \"LogisticRegression\": {'C': [1.0], 'max_iter': [100], 'solver': ['lbfgs'], 'random_state': [42]},\n",
    "    \"GaussianNB\": [{}],\n",
    "    \"SVC\": {'C': [1.0], 'kernel': ['rbf'], 'probability': [True], 'random_state': [42]},\n",
    "    \"ExtraTreesClassifier\": {'n_estimators': [100], 'max_depth': [10], 'random_state': [42]}\n",
    "}\n",
    "\n",
    "# Modelos\n",
    "from sklearn.base import clone\n",
    "\n",
    "modelos = {\n",
    "    \"LogisticRegression\": LogisticRegression(),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(),\n",
    "    \"LGBMClassifier\": LGBMClassifier(),\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier(),\n",
    "    \"GradientBoostingClassifier\": GradientBoostingClassifier(),\n",
    "    \"GaussianNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"ExtraTreesClassifier\": ExtraTreesClassifier(),\n",
    "}\n",
    "\n",
    "# Entrenamiento y tracking\n",
    "for nombre, modelo in modelos.items():\n",
    "    grid = params.get(nombre, [{}])\n",
    "    for param_set in ParameterGrid(grid):\n",
    "        m = clone(modelo)\n",
    "        m.set_params(**param_set)\n",
    "\n",
    "        with mlflow.start_run(run_name=nombre):\n",
    "            print(f\"Entrenando {nombre} con par√°metros: {param_set}\")\n",
    "            m.fit(X_train_res, y_train_res)\n",
    "\n",
    "            y_train_pred = m.predict(X_train_res)\n",
    "            y_test_pred = m.predict(X_test)\n",
    "\n",
    "            acc_train = accuracy_score(y_train_res, y_train_pred)\n",
    "            acc_test = accuracy_score(y_test, y_test_pred)\n",
    "            f1_train = f1_score(y_train_res, y_train_pred, average='weighted')\n",
    "            f1_test = f1_score(y_test, y_test_pred, average='weighted')\n",
    "            acc_gap = acc_train - acc_test\n",
    "            f1_gap = f1_train - f1_test\n",
    "\n",
    "            report = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "            recall_0 = report.get('0.0', {}).get('recall', 0)\n",
    "            recall_1 = report.get('1.0', {}).get('recall', 0)\n",
    "\n",
    "            # MLflow logs\n",
    "            mlflow.log_param(\"modelo\", nombre)\n",
    "            mlflow.log_params(param_set)\n",
    "            mlflow.log_metric(\"accuracy_train\", acc_train)\n",
    "            mlflow.log_metric(\"accuracy_test\", acc_test)\n",
    "            mlflow.log_metric(\"f1_train\", f1_train)\n",
    "            mlflow.log_metric(\"f1_test\", f1_test)\n",
    "            mlflow.log_metric(\"acc_gap\", acc_gap)\n",
    "            mlflow.log_metric(\"f1_gap\", f1_gap)\n",
    "            mlflow.log_metric(\"recall_0\", recall_0)\n",
    "            mlflow.log_metric(\"recall_1\", recall_1)\n",
    "\n",
    "            # Guardar el modelo\n",
    "            mlflow.sklearn.log_model(m, artifact_path=\"modelo\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run popular-pig-977 at: http://localhost:5000/#/experiments/168441151506597017/runs/e866290e5a28448e8011f8c5a706787f\n",
      "üß™ View experiment at: http://localhost:5000/#/experiments/168441151506597017\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "import mlflow\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # ... tu c√≥digo del modelo ...\n",
    "\n",
    "    ram_usage = psutil.virtual_memory().used / (1024 ** 3)  # en GB\n",
    "    cpu_usage = psutil.cpu_percent()\n",
    "\n",
    "    mlflow.log_metric(\"ram_used_gb\", ram_usage)\n",
    "    mlflow.log_metric(\"cpu_percent\", cpu_usage)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
